{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2b93fc2",
   "metadata": {},
   "source": [
    "# Setting up our Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a926da3c",
   "metadata": {},
   "source": [
    "In this notebook, the setup and exploration of the environment heavily follows Nicholas Renotte's YouTube tutorial *Build an Mario AI Model with Python | Gaming Reinforcement Learning* at: https://www.youtube.com/watch?v=2eeYqJ0uBKE&t=1982s\n",
    "\n",
    "The implementation of the REINFORCE algorithm is a modified version of the example script found in *Deep Reinforcement Learning with Python*.\n",
    "\n",
    "Pertinent Links:\n",
    "\n",
    "Super Mario RL: https://pypi.org/project/gym-super-mario-bros/\n",
    "\n",
    "Nes Py: https://pypi.org/project/nes-py/\n",
    "\n",
    "OpenAI Gym: https://gym.openai.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a9d763e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Imports\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# RL\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras import Model\n",
    "import gym\n",
    "import numpy as np\n",
    "import seaborn_image as isns\n",
    "from scipy.signal import convolve, gaussian\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms as T\n",
    "\n",
    "# Misc\n",
    "import os\n",
    "import io\n",
    "import base64\n",
    "import time\n",
    "import glob\n",
    "from PIL import Image\n",
    "# from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5435f582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the game\n",
    "import gym_super_mario_bros\n",
    "\n",
    "# Import the Joypad wrapper\n",
    "from nes_py.wrappers import JoypadSpace # Needed for changing the action space\n",
    "\n",
    "# Import the SIMPLIFIED controls\n",
    "from gym_super_mario_bros.actions import RIGHT_ONLY, SIMPLE_MOVEMENT, COMPLEX_MOVEMENT\n",
    "\n",
    "# Misc\n",
    "from gym.spaces import Box\n",
    "from gym.wrappers import FrameStack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d75a6e1",
   "metadata": {},
   "source": [
    "# REINFORCE Review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c60f16a",
   "metadata": {},
   "source": [
    "## Basic Overview of Policy Gradient Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b536bff",
   "metadata": {},
   "source": [
    "The REINFORCE algorithm starts from the concept of a trajectory, $\\large \\tau$, generated by an agent taking actions in states according to some policy parameterized (and therefore, an estimate) by $\\mathbf{\\theta}$:\n",
    "$$a \\sim \\hat{\\pi}(s, \\mathbf{\\theta})$$\n",
    "\n",
    "This action could be discrete, as in this script, in which case the output of $\\hat{\\pi}(s, \\mathbf{\\theta})$ is then a *Categorical Distribution* and the action must then be *sampled*, or, in the continuous case, a $d$-dimensional multivariate normal distribution.\n",
    "\n",
    "The agent follows the policy and generates the trajectory $\\large \\tau$: \n",
    "\n",
    "$$ s_1 \\rightarrow a_1 \\rightarrow s_2 \\rightarrow a_2 \\rightarrow .... \\rightarrow s_{T-1} \\rightarrow a_{T-1} \\rightarrow s_T \\rightarrow a_T$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29952383",
   "metadata": {},
   "source": [
    "The probability of trajectory $\\large \\tau$ depends on the transition probabilities $p(s_t+1 | s_t, a_t)$ and the policy $\\hat{\\pi}(s, \\mathbf{\\theta})$. It is given by the expression:\n",
    "\n",
    "$$p_\\theta(\\tau) = p_\\theta(s_1, a_1, s_2, a_2, ..., s_T, a_T) = p(s_1)\\prod_{t=1}^{T}\\hat{\\pi}(a_t|s_t,\\mathbf{\\theta})p(s_{t+1}|s_t,a_t)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9c0c6e",
   "metadata": {},
   "source": [
    "The expected return, which will generally be (or some variation thereof) our objective function $J$, from following the policy $\\pi$ is given by:\n",
    "\n",
    "$$J(\\theta) = R(\\theta)_{expected} = \\mathbf{E}_{\\tau \\sim p_\\mathbf{\\theta}(\\tau)} \\left[ \\sum_{t=1}^{T} \\gamma^{t-1} r_{t+1} \\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a4ef6f",
   "metadata": {},
   "source": [
    "After some mathematical manipulation, we can calculate $\\nabla_{\\theta} J(\\theta)$ as:\n",
    "\n",
    "$$\\nabla_{\\theta} J(\\theta) =  \\mathbf{E}_{\\tau \\sim p_\\theta(\\tau)} \\left[ \\left( \\sum_{t=1}^{T} \\nabla_{\\theta} \\log{ \\hat{\\pi}(a_t|s_t,\\mathbf{\\theta})} \\right) \\left( \\sum_{t=1}^{T} \\gamma^{t-1} r_{t+1} \\right) \\right] $$\n",
    "\n",
    "We can now replace the outer expectation with an estimate over multiple trajectories to get the following expression for the gradient of policy objective:\n",
    "\n",
    "$$\\nabla_{\\theta} J(\\theta) \\approx  \\frac{1}{N} \\sum_{i=1}^{N} \\left[ \\left( \\sum_{t=1}^{T} \\nabla_{\\theta} \\log{ \\hat{\\pi}_\\theta(a_t^i|s_t^i,\\mathbf{\\theta})} \\right) \\left( \\sum_{t=1}^{T} \\gamma^{t-1} r_{t+1} \\right) \\right] $$\n",
    "\n",
    "where i denotes the $i^{th}$ trajectory. \n",
    "\n",
    "Finally, we will use *Gradient Ascent*, as opposed to the normal *Descent*:\n",
    "\n",
    "$$\\mathbf{\\theta}_{k+1}=\\mathbf{\\theta}_k+\\eta \\nabla _{\\mathbf{\\theta}_k} J(\\mathbf{\\theta}_k)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5b59aa",
   "metadata": {},
   "source": [
    "## Rewards to Go Trick\n",
    "\n",
    "\n",
    "We drop the reward terms that came before time t as at time t, the action we take can only impact the reward which comes at time t and later. This leads to changing the 2nd inner sum going from $t’=t$ to $T$ instead of earlier sum over $t’$ going from $t’=1$ to $T$. i.e. the start index is now $t’=t$ and not $t=1$. The revised expression is given below:\n",
    "\n",
    "\n",
    "$$\\nabla_{\\theta} J(\\theta) \\approx  \\frac{1}{N} \\sum_{i=1}^{N} \\left[  \\sum_{t=1}^{T}  \\left( \\nabla_{\\theta} \\log{ \\hat{\\pi}(a_t^i|s_t^i, \\mathbf{\\theta})} \\right) \\left( \\sum_{t'=t}^{T} \\gamma^{t'-t} r_{t'+1}^i \\right) \\right] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b5240a",
   "metadata": {},
   "source": [
    "However, we note that $\\sum_{t'=t}^{T} \\gamma^{t'-t} r_{t'+1}^i$ is just the Q-value of the state and action at time $t'=t$, so we can replace it with $Q_t ^i = \\sum_{t'=t}^{T} \\gamma^{t'-t} r_{t'+1}^i$. We now have:\n",
    "\n",
    "$$\\nabla_{\\theta} J(\\theta) \\approx  \\frac{1}{N} \\sum_{i=1}^{N} \\left[ \\sum_{t=1}^{T}   \\nabla_{\\theta} \\log{ \\hat{\\pi}(a_t^i|s_t^i, \\mathbf{\\theta})} Q_t ^i \\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf0a0b4",
   "metadata": {},
   "source": [
    "## Entropy and Regularization with Rewards to Go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acd4e86",
   "metadata": {},
   "source": [
    "We will implement a pseudo loss function, whose derivative will give us $\\nabla_{\\theta} R(\\theta)$. Also. as PyTorch/TensorFlow carryout a gradient Step, we will convert maximization to minimization by changing the sign of this objective function.\n",
    "\n",
    "$$\\mathcal{L}_{CrossEntropy}(\\theta) = - J_{approx}(\\theta) = - \\frac{1}{N} \\sum_{i=1}^{N} \\left[ \\sum_{t=1}^{T} \\log{ \\pi(a_t^i|s_t^i,\\mathbf{\\theta})}  Q_t ^i \\right]$$\n",
    "\n",
    "To summarize, we will pass the state `s` through the network to get $\\log{ \\pi(s_t^i,\\mathbf{\\theta})}$. We will calculate the cross-entropy loss for the actions actually seen in the trajectory. We will then calculate the weighted mean of these individual loss terms in the trajectory with weights being the rewards-to-go $\\sum_{t'=t}^{T} \\gamma^{t'-t} r_{t'+1}^i$\n",
    "\n",
    "This will be followed by a gradient step in -ve direction of weighted NLL (negative log loss) i.e. in positive direction of the gradient of $J(\\theta)= - \\mathcal{L}_{Cross Entropy}(\\theta)$ \n",
    "\n",
    "We also add a regularization term known as Entropy. The entropy of a distribution is defined as:\n",
    "\n",
    "$$H(X) = \\beta \\sum_{x \\in X} -p(x)log(p(x))$$\n",
    "\n",
    "To keep enough exploration, we will want the probability to have a spread out distribution and not let the probability distribution to collapse to a single value or a small region too soon. BIgger the spread of a distribution, higher the entropy $H(x)$ of a distribution. Accordingly, the term fed into PyTorch/TensorFlow minimizer is:\n",
    "\n",
    "\n",
    "$$\\mathcal{L}(\\theta) = - J_{approx}(\\theta) - H(\\mathcal{A}) = - \\frac{1}{N} \\sum_{i=1}^{N} \\left[ \\sum_{t=1}^{T} \\log{ \\pi(a_t^i|s_t^i,\\mathbf{\\theta})}  Q_t ^i - \\beta \\sum_{a \\in \\mathcal{A}} \\pi(a|s_t^i,\\mathbf{\\theta})\\log{ \\pi(a|s_t^i,\\mathbf{\\theta})} \\right] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8422e4",
   "metadata": {},
   "source": [
    "# Exploring the game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "960f4c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the game\n",
    "\n",
    "env = gym_super_mario_bros.make('SuperMarioBros-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e18042fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RIGHT_ONLY action space: [['NOOP'], ['right'], ['right', 'A'], ['right', 'B'], ['right', 'A', 'B']]\n",
      "\n",
      "\n",
      "The SIMPLE_ACTION action space: [['NOOP'], ['right'], ['right', 'A'], ['right', 'B'], ['right', 'A', 'B'], ['A'], ['left']]\n",
      "\n",
      "\n",
      "The COMPLEX_ACTION action space: [['NOOP'], ['right'], ['right', 'A'], ['right', 'B'], ['right', 'A', 'B'], ['A'], ['left'], ['left', 'A'], ['left', 'B'], ['left', 'A', 'B'], ['down'], ['up']]\n"
     ]
    }
   ],
   "source": [
    "# Exploring the types of movement\n",
    "\n",
    "print('The RIGHT_ONLY action space:', RIGHT_ONLY)\n",
    "print('\\n')\n",
    "print('The SIMPLE_ACTION action space:', SIMPLE_MOVEMENT)\n",
    "print('\\n')\n",
    "print('The COMPLEX_ACTION action space:', COMPLEX_MOVEMENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9015fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 256, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploring the observation space\n",
    "\n",
    "env.observation_space.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d649d0",
   "metadata": {},
   "source": [
    "So, we have each frame being 240 $\\times$ 256 pixels with 3 channnels (RBG).\n",
    "\n",
    "Let's choose the simple movements for ease of training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3505e1f9",
   "metadata": {},
   "source": [
    "## Random Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99298cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking random actions\n",
    "\n",
    "def random_actions(game, movement, num_actions, render):\n",
    "    \n",
    "    \"\"\"\n",
    "    game is the game name.\n",
    "    movements is the type of movement where there are options. 'None' will skip this.\n",
    "    num_actions is the number of steps.\n",
    "    render determines if the game will be displayed, determined with True\n",
    "    \"\"\"\n",
    "    rewards = []\n",
    "    done = True\n",
    "    env = gym_super_mario_bros.make(game)\n",
    "    if movement != 'None':\n",
    "        env = JoypadSpace(env, movement)\n",
    "\n",
    "    # Loop through each frame in the game\n",
    "    for step in range(num_actions): \n",
    "        # Start the game to begin with \n",
    "        if done == True: \n",
    "            env.reset()\n",
    "        # Do random actions\n",
    "        state, reward, done, info = env.step(env.action_space.sample())\n",
    "        if render == True:\n",
    "            env.render()\n",
    "        rewards.append(reward)\n",
    "         \n",
    "    # Close the game and return the rewards\n",
    "    env.close()\n",
    "    return np.sum(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbb368b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\anaconda3\\lib\\site-packages\\pyglet\\image\\codecs\\wic.py:289: UserWarning: [WinError -2147417850] Cannot change thread mode after it is set\n",
      "  warnings.warn(str(err))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reward in this trajectory is: 759\n"
     ]
    }
   ],
   "source": [
    "print('The reward in this trajectory is:', random_actions('SuperMarioBros-v0', SIMPLE_MOVEMENT, 1000, True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9d8ed0",
   "metadata": {},
   "source": [
    "# Preprocessing the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "734622bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing wrappers\n",
    "\n",
    "# Frame Stacker Wrapper and GrayScaling Wrapper\n",
    "from gym.wrappers import GrayScaleObservation\n",
    "from stable_baselines3.common.vec_env import VecFrameStack, DummyVecEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2660b2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the environment\n",
    "\n",
    "def set_up_env(game, movement, grayscale, frame_stacking, frames, order):\n",
    "\n",
    "    env = gym_super_mario_bros.make(game)\n",
    "    env = JoypadSpace(env, movement)\n",
    "    if grayscale == True:\n",
    "        env = GrayScaleObservation(env, keep_dim=True)\n",
    "    env = DummyVecEnv([lambda: env])\n",
    "    if frame_stacking == True:\n",
    "        env = VecFrameStack(env, frames, channels_order=order)\n",
    "        \n",
    "    return env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07321e71",
   "metadata": {},
   "source": [
    "### Exploring what the GrayScaleObservation and VecFrameStack do"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a76a30",
   "metadata": {},
   "source": [
    "#### VecFrameStack and GrayScaleObservation turned off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e07e582b",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = set_up_env('SuperMarioBros-v0', SIMPLE_MOVEMENT, False, False, 4, 'last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2b4d4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State Shape (1, 240, 256, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARUAAAD4CAYAAADCQ3IKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAUTElEQVR4nO3df4jc9Z3H8ee7u2qwhotWo0sSMK0BTwtGIyHgoTmb1lSEbKmFLVgi9IgBPSpc/livB5Wjgdxhex54dmtPSTiLQWKbBFtymtg0tNDapI2aaL1sG6nbbE2vkms8ib1J3/fHfL+73539zu/PzPczM68HLDPz/X4/83nPd2Zf+/1+vt/vrLk7IiKhfKjoAkSkvyhURCQohYqIBKVQEZGghosuwMx+AVwBTBZdi4jMcw3we3e/sdEGhYcKcMWFC/5iyUdGblhSdCEiMtcfpl/hT+f+p6k2MYTK5EdGbliy4b6Xiq5DRCrs+ebtTJ881NRehMZURCQohYqIBKVQEZGgFCoiEpRCRUSCUqiISFAKFREJSqEiIkEpVEQkKIWKiASlUBGRoBQqIhKUQkVEgurrUHlsS/knez99nDc/b3q70/KWkXz11me99y+vba3nrvecodR6zkZfc63XGZu+DpVUtQ8TwAOPzN7G/mYNkqLei/TzEMNnIYYaWhHD96lEr1ff3F6Vt/XY6nP0q+zrS4MwFgMTKtW2RGp9+GJ+4yRfv71n1T63Mb+2gdj9qfUGPPDI7E+tdv3+ly82rf7StPvLVrlbXKQYamjFwGyptCr7l+KxLfl/ObIfxHR+v/3F7KZq41yNrtvscpXzaw2Y1nrO0Gp9hlppH9NnzIr+t6dmdnBk+a236TtqReKTfEftD919baNtBmJLpdZfgVp/oVqd106f7XjsqvUM37ufzdtKzbVr43UWoZ1dlJh2b6Cxdd/Nz1AIfT+mkt0EztvkrDaeUjmv8lyGavPa6bMdj121HoDS9nVMjDf+t6Kd19lrYqu/3kGCbn+GQunrUMlL82qHKyvHTirnpdNrzWunz05qZBwhrSedXu919qKYfgmb3Qop+jPUjIHY/Rl02Q9mTL9YofXKodfKrcHs/RjrbVZfb6nUOkyc95e31rx0eq157fTZaXlHrtp5nTHKnh4Q8+5BtRpj/ww1aiCO/gzCQO3E+DCl7esYvnc/U/cs4qsf/+85/dXqp5cGalvdGqm2ixDTa4pxoLaVoz8DESqDYmJ8eF6giLRDh5QH3OZtJb5adBEy8Pp6TEVEuk+hIiJBKVREJKi6oWJmy8zsB2b2hpkdN7MvJdMvM7MXzexEcntpps1DZjZpZm+a2R2dfAEiEpdGtlRKwN+5+18Ca4D7zew6YBw44O4rgAPJY5J5Y8D1wHrgcTMb6kTxIhKfuqHi7tPu/vPk/lngDWAJsAHYkSy2AxhN7m8Adrr7B+5+EpgEVgeuW0Qi1dSYipldDdwI/BS40t2noRw8wOJksSXA25lmU8m0yufaZGaHgVXvn51uvnIRiVLDoWJmlwDPAQ+6+x9rLZozbd4Zdu7+hLvfDBy5eOFIo2WISOQaChUzu4ByoHzb3b+TTH7HzEaS+SPA6WT6FLAs03wpcCpMuSISu0aO/hjwJPCGu389M2svsDG5vxHYk5k+ZmYXmdlyYAXwcriSRSRmjZymfwvwBeA1MzuaTPt7YBvwrJl9EfgN8DkAdz9uZs8Cr1M+cnS/u58PXbiIxKluqLj7j8gfJwH4RJU2W4GtbdQlIj1KZ9SKSFAKFREJSl99INGr/CLvZv9bgHSXQkWilAZJqVTisS1zQ2R4eFjBEjHt/kh0JsaHKZVKlEq1g6OZf0Ui3aN3RXpOqVRieHh45lZbLXHRlor0lLUHy7fpVkypVNIWS2QUKhKVdNcntfbgbJAAHFzb7YqkWYp4iUZeoChEeo+2VKRwE+PD8wIFGg+Uyl0g7Q4VS6EihWr0SE+zz6dgKY7WvBQmb+ukVdkjQlIshYp0XfbEtpCyz5fe1yHn7lOoSFeF3DqROGlMRUSCUqhIV23eVh776Abt+hRDoSJdVxks2ZPb6mlmWQVKMRQqUohssBxcOxsWtUKj2ZPhdFi5GAoVKUyjwZI9VT9vXjU6X6UYWuMSjXQrpPJ6n+z8Zq8F0i5Q92lLRQqVbq1kx1gOrp0bFtnHldNr6daAsMyltS6FS7cmKs+IzYZGdl5emGTnp2GirZRimPu8/0ja3QLMDo4sv/W2Dfe9VGgdEpfsWEhlONSaJ2Ht+ebtTJ889EN3X9toG22pSJRqhYWCJG4aUxGRoBQqIhKUQkVEglKoiEhQChURCUqhIiJBKVREJCiFiogEpVARkaAUKiISlEJFRIJSqIhIUHVDxcyeMrPTZnYsM+1hM/utmR1Nfu7MzHvIzCbN7E0zu6NThYtInBrZUtkOrM+Z/i/uvjL5+T6AmV0HjAHXJ20eN7OhUMWKSPzqhoq7HwLebfD5NgA73f0Ddz8JTAKr26hPRHpMO2MqD5jZq8nu0aXJtCXA25llppJp85jZJjM7DKx6/+x0G2WISExaDZVvAB8DVgLTwNeS6ZazbO5Xy7n7E+5+M3Dk4oUjLZYhIrFpKVTc/R13P+/ufwa+xewuzhSwLLPoUuBUeyWKSC9pKVTMLLtp8RkgPTK0Fxgzs4vMbDmwAni5vRJFpJfU/Y5aM3sGWAtcbmZTwFeAtWa2kvKuzVvAfQDuftzMngVeB0rA/e5+viOVi0iU6oaKu38+Z/KTNZbfCmxtpygR6V06o1ZEglKoiEhQChURCUqhIiJBKVREJCiFiogEpVARkaAUKiISlEJFRIJSqIhIUAoVEQlKoSIiQSlURCQohYqIBKVQEZGgFCoiEpRCRUSCUqiISFAKFREJSqEiIkEpVEQkKIWKiASlUBGRoBQqIhKUQkVEglKoiEhQChURCUqhIiJBKVREJCiFiogEpVARkaAUKiISlEJFRIJSqIhIUAoVEQlKoSIiQSlURCSouqFiZk+Z2WkzO5aZdpmZvWhmJ5LbSzPzHjKzSTN708zu6FThIhKnRrZUtgPrK6aNAwfcfQVwIHmMmV0HjAHXJ20eN7OhYNWKSPTqhoq7HwLerZi8AdiR3N8BjGam73T3D9z9JDAJrA5Tqoj0glbHVK5092mA5HZxMn0J8HZmualk2jxmtsnMDgOr3j873WIZIhKb0AO1ljPN8xZ09yfc/WbgyMULRwKXISJFaTVU3jGzEYDk9nQyfQpYllluKXCq9fJEpNe0Gip7gY3J/Y3Ansz0MTO7yMyWAyuAl9srUUR6yXC9BczsGWAtcLmZTQFfAbYBz5rZF4HfAJ8DcPfjZvYs8DpQAu539/Mdql1EIlQ3VNz981VmfaLK8luBre0UJSK9S2fUikhQChURCUqhIiJBKVREJCiFiogEpVARkaAUKiISlEJFRIJSqIhIUAoVEQlKoSIiQSlURCQohYqIBKVQEZGgFCoiEpRCRUSCUqiISFAKFREJSqEiIkEpVEQkKIWKiASlUBGRoBQqIhKUQkVEgqr7z8QGycT4/NWxeVupgEpEetfAh8qcINmZM39sdr4CRqS+gQ2VmTDJCZI5MvMnxoYVLCJ1DOSYysT4cDks6gVK1lh5+bxdJBGZNXChMhMozRjL3CpYRGoaqFBpKVDyKFhEqhqIUJkYH2bi6iYDZYzZLZQ8O2Hi6mGFi0iFgQiVtrdOdlbcVsxTsIjM6vtQCfYLXyuYFCwiM/o6VIKNoTRCwSIC9HGotB0ozR5yTtooWGTQ9WWodHULpZKCRQZcW6FiZm+Z2WtmdtTMDifTLjOzF83sRHJ7aZhSG1NooKSK7l+kQCG2VP7a3Ve6+83J43HggLuvAA4kj7siikBJaGtFBlUndn82ADuS+zuA0Q70MU9MgQJoN0gGVruh4sALZnbEzDYl065092mA5HZxXkMz25TsMq16/+x0W0VEFygpBYsMoHY/8be4+ykzWwy8aGa/bLShuz8BPGFmBy9eOHJbK523dGFgt+2ECYZhTF+dIIOhrVBx91PJ7Wkz+y6wGnjHzEbcfdrMRoDTAerM18qFgZ0IoEaed6e+OmEQVG6ZNvN+t9q2nT47oeVQMbMPAx9y97PJ/U8B/wjsBTYC25LbPSEKrdT0Lk/FlcbNOvfo3McLHmzheRUsfW/fuavmPF6/oLH3e2J8eF7b3Y92ts9OaWdM5UrgR2b2CvAy8D1330c5TD5pZieATyaPg+r2GEploKTTzj0K59Y0+WQaZ+lLE+P5F5fuO3dVzfc7bVcZDOm8TvTZaS337O6/Bm7Imf4H4BPtFFVLEYOyz6+bvT96zTp2T+5n9Jp1DC/YX/tK5mq0xdJXqoVC3nLZ97zVdu227bSeOqO2rS9YatGuY+UggdnbVOncOkrb1+U1q09bLAMj3XJodgui1Xbttm1Xz4RKkGt5srct2D25H5jdWkmVtq9r7XljPmolbVu/+3cz99Otika2LrJts+0aCYd2+gylJ0Il5De2tSLd3Um3VNJA2T25n92T+8u7QS3S1kpvq9wNmfNLPXrVnMf12lW2Dd1nt0T/iS76xLa7P16+LZ2bnZbdDWonUACNr/SwvF/uyjDIC4dG2oXus5vM3YstwOzgyPJbb9tw30vz5hUdKKldx8q3d+2fHbRNwyYYnRzXE7Jblt3erWjH+gW/m/l8NTN4u+ebtzN98tAP3X1to31Fu6XS9HfKdkAaJll3JRsmuyqmtx0yOvM2aukWwuiDvRMkWfvOXcX6BbOvoZPnskQ5phLLOEN2HOWu/TC8uXx/ePO6mXDJLhOEjgpFqZe2Sqpp5VyYVkQXKrHs8mSloVGa2D/nNmiYZClYotKP70UnDzlHFSoxBgrMhkij04NQsESh0ZPMelGnXlc0oRJjoAwvmH+4eOaanxrLBKNgkR4UxSd2+uSh6AIltevY/CM+Cx6cHcTddawDR4KydgJvdfD5pabN20ozA5z9KHtUKJQoQmXN4iH2Xftc1fmLVo4ydc8iLtmyfc709x65d960vLZnju6e1w6o2XbRylF2/cPcaWeu3T3T5/5jozPTdx2DdXfvntO21T5zX+fzl3f0dRaxbnupz4lxWPPLia722a3XeeYowPNV+zz69R/T7FeoRREqQ8uunVlh1VyyZfu8ZfKm5alcZunTZzhzdHfdtuvunrtM+sa898i9rGFRzT5a7bOI16k+1We1Pn9y+nzdNpWiGVMRkf6gUBGRoKLY/WnEe4/cy9Knz8yZdmZLY20r203ds0h9qk/12UCfaxYPNb0L1DOhcsmW7Q2vmEqVg0+LVo429FzqU32qz9Gmn6NnQgXmDyLVG0Gv1k59qk/1Gb7PlMZURCQohYqIBBVFqPz4yPF5A0SpWsfmF60crdou2zZPrbbqU32qz9ZFMaZyy6rr+d6TW2cGhRod5U5XQrPt2mmrPtXnoPXZrChCBcoDRJUvHKh7BmG1du20VZ/qU322LppQgdmR52ovvNF27bRVn+pTfbYnqlBJNZKYS58+M+9YfKPt1Kf6VJ+t91lPFF98vWbx0G37XojvKmX1qT4Hvc/1n/osPzl9vve++DrWq5TVp/oc9D51lbKIFE6hIiJB9VSotDpw1Go79ak+1WfzohhTaUS6r5d90c1ciZlt18wl5OpTfQ5yn/rqgypiuYRcfarPXuyzWT0TKlDM5dzqU32qz+b01JiKiMRPoSIiQUUTKpds2c7Sp8/MG32ud8JPtXbZtupTfarP9vpsRsfGVMxsPfCvwBDw7+6+rdbyg3K1p/pUn73YZzM6EipmNgT8G/BJYAr4mZntdffXa7WrvIKyX6/2VJ/qsxf7bFSntlRWA5Pu/msAM9sJbABqhkqq0Ssoe/1qT/WpPnuxz7rcPfgPcDflXZ708ReAxyqW2QQcBv60YAiH+T9rFg/5Lauuz52Xzq81r1rbNYuHqrZVn+pTfc7+LLwAB6aa+f3vyFcfmNnngDvc/W+Sx18AVrv73+Ys+wvgCuB/oen/BV20EVRzt/Ri3f1Q8zXA7939xkafoFO7P1PAsszjpcCpvAXTYs3scDPf2RAD1dw9vVj3oNbcqUPKPwNWmNlyM7sQGAP2dqgvEYlIR7ZU3L1kZg8A/0n5kPJT7n68E32JSFw6dp6Ku38f+H4TTZ7oVC0dpJq7pxfrHsiaC/+OWhHpL9Gcpi8i/UGhIiJBFR4qZrbezN40s0kzGy+6nlrM7C0ze83MjprZ4WTaZWb2opmdSG4vLbjGp8zstJkdy0yrWqOZPZSs+zfN7I6Ian7YzH6brOujZnZnZDUvM7MfmNkbZnbczL6UTI92XdeoOey67sQZtU2ceTsE/Ar4KHAh8ApwXZE11an3LeDyimn/DIwn98eBfyq4xluBm4Bj9WoErkvW+UXA8uS9GIqk5oeBLTnLxlLzCHBTcn8h8F9JbdGu6xo1B13XRW+pzFwj5O5/AtJrhHrJBmBHcn8HMFpcKeDuh4B3KyZXq3EDsNPdP3D3k8Ak5fekq6rUXE0sNU+7+8+T+2eBN4AlRLyua9RcTUs1Fx0qS4C3M4+nqP0ii+bAC2Z2xMw2JdOudPdpKL9pwOLCqquuWo2xr/8HzOzVZPco3Y2IrmYzuxq4EfgpPbKuK2qGgOu66FCxnGkxH+O+xd1vAj4N3G9mtxZdUJtiXv/fAD4GrKR8LcrXkulR1WxmlwDPAQ+6+x9rLZozrZC6c2oOuq6LDpWGrxGKgbufSm5PA9+lvCn4jpmNACS3p4ursKpqNUa7/t39HXc/7+5/Br7F7GZ3NDWb2QWUfzm/7e7fSSZHva7zag69rosOlZ65RsjMPmxmC9P7wKeAY5Tr3ZgsthHYU0yFNVWrcS8wZmYXmdlyYAXwcgH1zZP+YiY+Q3ldQyQ1m5kBTwJvuPvXM7OiXdfVag6+rrs9ap4zwnwn5VHoXwFfLrqeGnV+lPJI+CvA8bRW4CPAAeBEcntZwXU+Q3kT9v8o/6X5Yq0agS8n6/5N4NMR1fwfwGvAq8mHeySymv+K8q7Aq8DR5OfOmNd1jZqDrmudpi8iQRW9+yMifUahIiJBKVREJCiFiogEpVARkaAUKiISlEJFRIL6f261BXHlA0WhAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "state = env.reset()\n",
    "print('State Shape', state.shape)\n",
    "plt.imshow(state[0]).origin='upper'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae790b4",
   "metadata": {},
   "source": [
    "#### GrayScaleObservation Off and VecFrameStack On"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a6797fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = set_up_env('SuperMarioBros-v0', SIMPLE_MOVEMENT, False, True, 4, 'last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bd55a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State Shape (1, 240, 256, 12)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "state = env.reset()\n",
    "print('State Shape', state.shape)\n",
    "for i in range(0,4): # Filling our vector with images\n",
    "    state, reward, done, info = env.step([env.action_space.sample()]) # Note that the brackets around the env.action... are\n",
    "# because we have wrapped it\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "for idx in range(12): # So there'll be 4 images with 3 channels\n",
    "    plt.subplot(1,12,idx+1)\n",
    "    plt.imshow(state[0][:,:,idx]).origin='upper' # idx is in ranging through 1-4\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a822790e",
   "metadata": {},
   "source": [
    "#### GrayScaleObservation and VecFrameStack On"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54690f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = set_up_env('SuperMarioBros-v0', SIMPLE_MOVEMENT, True, True, 4, 'last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73da04b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State Shape (1, 240, 256, 4)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "state = env.reset()\n",
    "print('State Shape', state.shape)\n",
    "for i in range(0,4): # Filling our vector with images\n",
    "    state, reward, done, info = env.step([env.action_space.sample()]) # Note that the brackets around the env.action... are\n",
    "# because we have wrapped it\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "for idx in range(state.shape[3]): # So there'll be 4 images\n",
    "    plt.subplot(1,4,idx+1)\n",
    "    plt.imshow(state[0][:,:,idx]).origin='upper' # idx is in ranging through 1-4\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06669b1c",
   "metadata": {},
   "source": [
    "## Setting up the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc17a585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7803dfa",
   "metadata": {},
   "source": [
    "# Setting up our agent to be trained with REINFORCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b70885b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State Shape: (240, 256, 4)\n",
      "Number of actions: 7\n"
     ]
    }
   ],
   "source": [
    "# Getting the observation and action shape for our neural net\n",
    "\n",
    "state_shape, n_actions = env.observation_space.shape, env.action_space.n\n",
    "state_dim = state_shape\n",
    "print('State Shape:', state_dim)\n",
    "print('Number of actions:',n_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a254d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining our neural network\n",
    "\n",
    "class RAgent(nn.Module):\n",
    "    def __init__(self, state_shape, n_actions):\n",
    "        super().__init__()\n",
    "        self.n_actions = n_actions\n",
    "        self.state_shape = state_shape\n",
    "        \n",
    "        self.conv = nn.Sequential(nn.Conv2d(in_channels=4, out_channels=32, kernel_size=8, stride=4),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2, padding=0),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=8, stride=4),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2, padding=0),\n",
    "            nn.Flatten())\n",
    "        self.fc = nn.Sequential(nn.Linear(288, n_actions))\n",
    "        \n",
    "    def forward(self, state_t):\n",
    "        x = self.conv(state_t)\n",
    "        x= self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "590fd52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating the agent\n",
    "\n",
    "agent = RAgent(state_shape, n_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5784d2",
   "metadata": {},
   "source": [
    "# Trajectory Calculations\n",
    "\n",
    "We will use this function to generate the trajectory. It will not be used for doing back propagation. So we will use PyTorch `no_grad()` to avoid gradient calculations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad1b344",
   "metadata": {},
   "source": [
    "## Generating Trajectory from Action Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "940658f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probability of the actions\n",
    "\n",
    "def predict_probs(states):\n",
    "    \"\"\"\n",
    "    params: states: [batch, state_dim] Note that in generate_trajectory, batch_size is 1, as it is finding the probabilities\n",
    "    for each step.\n",
    "    Feeds into agent and returns probs: [batch, n_actions]\n",
    "    \"\"\"\n",
    "    \n",
    "    states = torch.tensor(states, device=device, dtype=torch.float32)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        # Reshaping and rearranging the states\n",
    "        states = torch.squeeze(states)\n",
    "        states = states.transpose(0,2)\n",
    "        states = states.transpose(1,2)\n",
    "        states = states.unsqueeze(0)\n",
    "        \n",
    "        # Passing the states through the neural net for the logits\n",
    "        logits = agent(states)\n",
    "    probs = nn.functional.softmax(logits, -1).detach().numpy()\n",
    "    \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7baffe71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a trajectory\n",
    "\n",
    "def generate_trajectory(env, n_steps=512):\n",
    "    \"\"\"\n",
    "    Play a session and generate a trajectory of n_steps one step at a time\n",
    "    returns: arrays of states, actions, rewards\n",
    "    \"\"\"\n",
    "    states, actions, rewards = [], [], []\n",
    "    \n",
    "    # Initialize the environment\n",
    "    s = env.reset()\n",
    "    \n",
    "    # Generate n_steps of trajectory:\n",
    "    for t in range(n_steps):\n",
    "        action_probs = predict_probs(np.array([s]))[0]\n",
    "        \n",
    "        # Sample action based on action_probs\n",
    "        a = [np.random.choice(n_actions, p=action_probs)]\n",
    "\n",
    "        next_state, r, done, _ = env.step(a)\n",
    "        \n",
    "        # Update arrays\n",
    "        states.append(s)\n",
    "        actions.append(a)\n",
    "        rewards.append(r)\n",
    "        \n",
    "        s = next_state\n",
    "        if done:\n",
    "            break\n",
    "    return states, actions, rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80c6181",
   "metadata": {},
   "source": [
    "## Calculate Rewards to Go\n",
    "\n",
    " $Q_t ^i = \\sum_{t'=t}^{T} \\gamma^{t-t'} r_{t'+1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7d2d061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rewards to Go\n",
    "\n",
    "def get_rewards_to_go(rewards, gamma=0.99):\n",
    "    \n",
    "    T = len(rewards) # Total number of individual rewards\n",
    "    # Empty array to return the rewards to go\n",
    "    rewards_to_go = [0]*T \n",
    "    rewards_to_go[T-1] = rewards[T-1]\n",
    "    \n",
    "    for i in range(T-2, -1, -1): # Go from T-2 to 0\n",
    "        rewards_to_go[i] = gamma * rewards_to_go[i+1] + rewards[i]\n",
    "    \n",
    "    return rewards_to_go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e48807",
   "metadata": {},
   "source": [
    "# REINFORCE Training\n",
    "\n",
    "We will calculate the loss and take a gradient step. We will use Adam Optimizer\n",
    "\n",
    "We are taking only one trajectory. so N=1. We will however, average it over the number of actions to get the average loss. So the function we will actually implement is as given below:\n",
    "\n",
    "$$Loss(\\theta) = - J(\\theta) - H(\\mathcal{A}) = - \\frac{1}{T} \\left[ \\sum_{t=1}^{T} \\log{ \\pi(a_t|s_t,\\mathbf{\\theta})}  Q_t - \\beta \\sum_{a \\in \\mathcal{A}} \\pi(a|s_t,\\mathbf{\\theta})\\log{ \\pi(a|s_t,\\mathbf{\\theta})} \\right] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639b8513",
   "metadata": {},
   "source": [
    "## Redefining our environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93abbed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = set_up_env('SuperMarioBros-v0', SIMPLE_MOVEMENT, True, True, 4, 'last')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acce071",
   "metadata": {},
   "source": [
    "## Single trajectory training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c1fe02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training over one trajectory\n",
    "\n",
    "# Intializing the optimizer\n",
    "optimizer = torch.optim.Adam(agent.parameters(), lr=1e-5)\n",
    "\n",
    "def train_one_trajectory(states, actions, rewards, gamma=0.99, entropy_coef=1e-2):\n",
    "    \n",
    "    # Get rewards to go\n",
    "    rewards_to_go = get_rewards_to_go(rewards, gamma)\n",
    "\n",
    "    # Convert numpy array to torch tensors\n",
    "    states = torch.tensor(states, device=device, dtype=torch.float)    \n",
    "    actions = torch.tensor(actions, device=device, dtype=torch.long)\n",
    "    rewards_to_go = torch.tensor(rewards_to_go, device=device, dtype=torch.float)\n",
    "\n",
    "    # Get action probabilities from states\n",
    "    logits = agent(states) # Get's logits for the possible actions in each state/step of the trajectory. \n",
    "    # Has shape [n_steps, n_actions_per_state]\n",
    "    probs = nn.functional.softmax(logits, -1) # Get's probabilities for the possible actions in each state/step of the\n",
    "    # trajectory. Has shape [n_steps, n_actions_per_state]\n",
    "    log_probs = nn.functional.log_softmax(logits, -1) # Get's log probabilities for the \n",
    "    # possible actions in each state/step of the trajectory. Has shape [n_steps, n_actions_per_state]\n",
    "    \n",
    "    log_probs_for_actions = log_probs[range(len(actions)), actions] # Log probabilities for the actions it ACTUALLY took.\n",
    "    # Has size [n_steps, n_steps]\n",
    "    \n",
    "    # Compute loss to be minimized\n",
    "    J = torch.mean(log_probs_for_actions*rewards_to_go) # Multiplies each log probability for the action ACTUALLY\n",
    "    # taken at step t the Rewards to Go from that step, then divides by the number of trajectories. Produces a single number\n",
    "    H = -(probs*log_probs).sum(-1).mean() # Multiplies each action's probability by its log probability in each step,\n",
    "    # sums them across each step, and then divides by the number of steps. Produces a single number\n",
    "    \n",
    "    loss = -(J+entropy_coef*H)\n",
    "\n",
    "    # Updating the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return np.sum(rewards) # To show progress in training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca7ebe4",
   "metadata": {},
   "source": [
    "## Train the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a2a2031",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Training function\n",
    "\n",
    "def reinforce_training(iterations):\n",
    "    \n",
    "    total_rewards = []\n",
    "    for i in range(iterations):\n",
    "        print('Step', i)\n",
    "        states, actions, rewards = generate_trajectory(env)    \n",
    "        states = torch.tensor(states).squeeze()\n",
    "        states = states.transpose(1,3)\n",
    "        states = states.transpose(2,3)\n",
    "        reward = train_one_trajectory(states, actions, rewards)\n",
    "        total_rewards.append(reward)\n",
    "        print('Reward this loop:', total_rewards[-1])\n",
    "    env.close()\n",
    "    print('List of rewards', total_rewards)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a5699d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the loop\n",
    "\n",
    "start = time.time()\n",
    "reinforce_training(200)\n",
    "end = time.time()\n",
    "print('The training took', round(end-start,3), 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec545ba",
   "metadata": {},
   "source": [
    "# Evaluation of the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8d27f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating our agent\n",
    "\n",
    "def evaluate_mario(n_steps, render):\n",
    "\n",
    "    rewards = []\n",
    "    \n",
    "    # Initialize the environment\n",
    "    env = set_up_env('SuperMarioBros-v0', SIMPLE_MOVEMENT, True, True, 4, 'last')\n",
    "    s = env.reset()\n",
    "    \n",
    "    # Generate n_steps of trajectory:\n",
    "    for t in range(n_steps):\n",
    "        action_probs = predict_probs(np.array([s]))[0]\n",
    "        \n",
    "        # Sample action based on action_probs\n",
    "        a = [np.random.choice(n_actions, p=action_probs)]\n",
    "\n",
    "        next_state, r, done, _ = env.step(a)\n",
    "        if render == True:\n",
    "            env.render()\n",
    "\n",
    "        rewards.append(r)\n",
    "        \n",
    "        s = next_state\n",
    "        if done:\n",
    "            break\n",
    "    env.close()\n",
    "\n",
    "    return np.sum(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "411201d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The agent recieved a total reward in one playthrough of 1912.0\n"
     ]
    }
   ],
   "source": [
    "# Single play-through\n",
    "\n",
    "print('The agent recieved a total reward in one playthrough of', evaluate_mario(1000, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b36d7b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average reward after 10 trajectories is 1360.4\n"
     ]
    }
   ],
   "source": [
    "# Multiple play-throughs\n",
    "\n",
    "rewards_list = []\n",
    "n_traj = 10\n",
    "for i in range(n_traj):\n",
    "    rewards_list.append(evaluate_mario(1000, False))\n",
    "print('The average reward after', n_traj, 'trajectories is', np.mean(rewards_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0952774d",
   "metadata": {},
   "source": [
    "# Saving and Reloading the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "824c7345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving an agent\n",
    "\n",
    "torch.save(agent, 'Models/REINFORCE.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b50498a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RAgent(\n",
       "  (conv): Sequential(\n",
       "    (0): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))\n",
       "    (1): Tanh()\n",
       "    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (3): Conv2d(32, 32, kernel_size=(8, 8), stride=(4, 4))\n",
       "    (4): Tanh()\n",
       "    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (6): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=288, out_features=7, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading an agent\n",
    "\n",
    "agent = torch.load('Models/REINFORCE.h5')\n",
    "\n",
    "# Confirming it has the architecture we want\n",
    "agent.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
