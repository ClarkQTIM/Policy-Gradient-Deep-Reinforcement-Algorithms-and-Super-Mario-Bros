{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2b93fc2",
   "metadata": {},
   "source": [
    "# Setting up our Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a926da3c",
   "metadata": {},
   "source": [
    "In this notebook, the setup and exploration of the environment heavily follows Nicholas Renotte's YouTube tutorial *Build an Mario AI Model with Python | Gaming Reinforcement Learning* at: https://www.youtube.com/watch?v=2eeYqJ0uBKE&t=1982s\n",
    "\n",
    "The implementation of the REINFORCE algorithm is a modified version of the example script found in *Deep Reinforcement Learning with Python*.\n",
    "\n",
    "Pertinent Links:\n",
    "\n",
    "Super Mario RL: https://pypi.org/project/gym-super-mario-bros/\n",
    "\n",
    "Nes Py: https://pypi.org/project/nes-py/\n",
    "\n",
    "OpenAI Gym: https://gym.openai.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a9d763e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Imports\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# RL\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras import Model\n",
    "import gym\n",
    "import numpy as np\n",
    "import seaborn_image as isns\n",
    "from scipy.signal import convolve, gaussian\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms as T\n",
    "\n",
    "# Misc\n",
    "import os\n",
    "import io\n",
    "import base64\n",
    "import time\n",
    "import glob\n",
    "from PIL import Image\n",
    "# from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5435f582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the game\n",
    "import gym_super_mario_bros\n",
    "\n",
    "# Import the Joypad wrapper\n",
    "from nes_py.wrappers import JoypadSpace # Needed for changing the action space\n",
    "\n",
    "# Import the SIMPLIFIED controls\n",
    "from gym_super_mario_bros.actions import RIGHT_ONLY, SIMPLE_MOVEMENT, COMPLEX_MOVEMENT\n",
    "\n",
    "# Misc\n",
    "from gym.spaces import Box\n",
    "from gym.wrappers import FrameStack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d75a6e1",
   "metadata": {},
   "source": [
    "# REINFORCE Review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c60f16a",
   "metadata": {},
   "source": [
    "## Basic Overview of Policy Gradient Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b536bff",
   "metadata": {},
   "source": [
    "The REINFORCE algorithm starts from the concept of a trajectory, $\\large \\tau$, generated by an agent taking actions in states according to some policy parameterized (and therefore, an estimate) by $\\mathbf{\\theta}$:\n",
    "$$a = \\hat{\\pi}(s, \\mathbf{\\theta})$$\n",
    "\n",
    "This action could be discrete, as in this script, in which case the output of $\\hat{\\pi}(s, \\mathbf{\\theta})$ is then a *Categorical Distribution* and the action must then be *sampled*, or, in the continuous case, a $d$-dimensional multivariate normal distribution.\n",
    "\n",
    "The agent follows the policy and generates the trajectory $\\large \\tau$: \n",
    "\n",
    "$$ s_1 \\rightarrow a_1 \\rightarrow s_2 \\rightarrow a_2 \\rightarrow .... \\rightarrow s_{T-1} \\rightarrow a_{T-1} \\rightarrow s_T \\rightarrow a_T$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29952383",
   "metadata": {},
   "source": [
    "The probability of trajectory $\\large \\tau$ depends on the transition probabilities $p(s_t+1 | s_t, a_t)$ and the policy $\\hat{\\pi}(s, \\mathbf{\\theta})$. It is given by the expression:\n",
    "\n",
    "$$p_\\theta(\\tau) = p_\\theta(s_1, a_1, s_2, a_2, ..., s_T, a_T) = p(s_1)\\prod_{t=1}^{T}\\hat{\\pi}(a_t|s_t,\\mathbf{\\theta})p(s_{t+1}|s_t,a_t)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9c0c6e",
   "metadata": {},
   "source": [
    "The expected return from following the policy $\\pi$ is given by:\n",
    "\n",
    "$$R(\\theta) = {\\large E}_{\\tau \\sim p_\\mathbf{\\theta}(\\tau)} \\left[ \\sum_{t=1}^{T} \\gamma^{t-1} r_{t+1} \\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a4ef6f",
   "metadata": {},
   "source": [
    "After some mathematical manipulation, we can calculate $\\nabla_{\\theta} J(\\theta)$ as:\n",
    "\n",
    "$$\\nabla_{\\theta} R(\\theta) =  {\\large E}_{\\tau \\sim p_\\theta(\\tau)} \\left[ \\left( \\sum_{t=1}^{T} \\nabla_{\\theta} \\log{ \\hat{\\pi}(a_t|s_t,\\mathbf{\\theta})} \\right) \\left( \\sum_{t=1}^{T} \\gamma^{t-1} r_{t+1} \\right) \\right] $$\n",
    "\n",
    "We can now replace the outer expectation with an estimate over multiple trajectories to get the following expression for the gradient of policy objective:\n",
    "\n",
    "$$\\nabla_{\\theta} R(\\theta) =  \\frac{1}{N} \\sum_{i=1}^{N} \\left[ \\left( \\sum_{t=1}^{T} \\nabla_{\\theta} \\log{ \\hat{\\pi}_\\theta(a_t^i|s_t^i,\\mathbf{\\theta})} \\right) \\left( \\sum_{t=1}^{T} \\gamma^{t-1} r_{t+1} \\right) \\right] $$\n",
    "\n",
    "where i denotes the $i^{th}$ trajectory. \n",
    "\n",
    "Finally, we will use *Gradient Ascent*, as opposed to the normal *Descent*:\n",
    "\n",
    "$$\\mathbf{\\theta}_{k+1}=\\mathbf{\\theta}_k+\\eta \\nabla _{\\mathbf{\\theta}_k} R(\\mathbf{\\theta}_k)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5b59aa",
   "metadata": {},
   "source": [
    "## Rewards to Go Trick\n",
    "\n",
    "\n",
    "We drop the reward terms that came before time t as at time t, the action we take can only impact the reward which comes at time t and later. This leads to changing the 2nd inner sum going from $t’=t$ to $T$ instead of earlier sum over $t’$ going from $t’=1$ to $T$. i.e. the start index is now $t’=t$ and not $t=1$. The revised expression is given below:\n",
    "\n",
    "\n",
    "$$\\nabla_{\\theta} R(\\theta) =  \\frac{1}{N} \\sum_{i=1}^{N} \\left[  \\sum_{t=1}^{T}  \\left( \\nabla_{\\theta} \\log{ \\hat{\\pi}(a_t^i|s_t^i, \\mathbf{\\theta})} \\right) \\left( \\sum_{t'=t}^{T} \\gamma^{t'-t} r_{t'+1}^i \\right) \\right] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b5240a",
   "metadata": {},
   "source": [
    "However, we note that $\\sum_{t'=t}^{T} \\gamma^{t'-t} r_{t'+1}^i$ is just the Q-value of the state and action at time $t'=t$, so we can replace it with $Q_t ^i = \\sum_{t'=t}^{T} \\gamma^{t'-t} r_{t'+1}^i$. We now have:\n",
    "\n",
    "$$\\nabla_{\\theta} R(\\theta) =  \\frac{1}{N} \\sum_{i=1}^{N} \\sum_{t=1}^{T}   \\nabla_{\\theta} \\log{ \\hat{\\pi}(a_t^i|s_t^i, \\mathbf{\\theta})} Q_t ^i $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf0a0b4",
   "metadata": {},
   "source": [
    "## Entropy and Regularization with Rewards to Go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acd4e86",
   "metadata": {},
   "source": [
    "We will implement a pseudo loss function, whose derivative will give us $\\nabla_{\\theta} J(\\theta)$. Also. as PyTorch/TensorFlow carryout a gradient Step, we will convert maximization to minimization by changing the sign of this objective function.\n",
    "\n",
    "$$\\mathcal{L}_{CrossEntropy}(\\theta) = - R(\\theta) = - \\frac{1}{N} \\sum_{i=1}^{N} \\sum_{t=1}^{T} \\log{ \\pi(a_t^i|s_t^i,\\mathbf{\\theta})}  Q_t ^i $$\n",
    "\n",
    "To summarize, we will pass the state `s` through the network to get $\\log{ \\pi(s_t^i,\\mathbf{\\theta})}$. We will calculate the cross-entropy loss for the actions actually seen in the trajectory. We will then calculate the weighted mean of these individual loss terms in the trajectory with weights being the rewards-to-go $\\sum_{t'=t}^{T} \\gamma^{t'-t} r_{t'+1}^i$\n",
    "\n",
    "This will be followed by a gradient step in -ve direction of weighted NLL (negative log loss) i.e. in positive direction of the gradient of $R(\\theta)= - \\mathcal{L}_{Cross Entropy}(\\theta)$ \n",
    "\n",
    "We also add a regularization term known as Entropy. The entropy of a distribution is defined as:\n",
    "\n",
    "$$H(X) = \\beta \\sum_{x \\in X} -p(x)log(p(x))$$\n",
    "\n",
    "To keep enough exploration, we will want the probability to have a spread out distribution and not let the probability distribution to collapse to a single value or a small region too soon. BIgger the spread of a distribution, higher the entropy $H(x)$ of a distribution. Accordingly, the term fed into PyTorch/TensorFlow minimizer is:\n",
    "\n",
    "\n",
    "$$\\mathcal{L}(\\theta) = - J(\\theta) - H(\\mathcal{A}) = - \\frac{1}{N} \\sum_{i=1}^{N} \\left[ \\sum_{t=1}^{T} \\log{ \\pi(a_t^i|s_t^i,\\mathbf{\\theta})}  Q_t ^i - \\beta \\sum_{a \\in \\mathcal{A}} \\pi(a|s_t^i,\\mathbf{\\theta})\\log{ \\pi(a|s_t^i,\\mathbf{\\theta})} \\right] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8422e4",
   "metadata": {},
   "source": [
    "# Exploring the game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "960f4c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the game\n",
    "\n",
    "env = gym_super_mario_bros.make('SuperMarioBros-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e18042fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RIGHT_ONLY action space: [['NOOP'], ['right'], ['right', 'A'], ['right', 'B'], ['right', 'A', 'B']]\n",
      "\n",
      "\n",
      "The SIMPLE_ACTION action space: [['NOOP'], ['right'], ['right', 'A'], ['right', 'B'], ['right', 'A', 'B'], ['A'], ['left']]\n",
      "\n",
      "\n",
      "The COMPLEX_ACTION action space: [['NOOP'], ['right'], ['right', 'A'], ['right', 'B'], ['right', 'A', 'B'], ['A'], ['left'], ['left', 'A'], ['left', 'B'], ['left', 'A', 'B'], ['down'], ['up']]\n"
     ]
    }
   ],
   "source": [
    "# Exploring the types of movement\n",
    "\n",
    "print('The RIGHT_ONLY action space:', RIGHT_ONLY)\n",
    "print('\\n')\n",
    "print('The SIMPLE_ACTION action space:', SIMPLE_MOVEMENT)\n",
    "print('\\n')\n",
    "print('The COMPLEX_ACTION action space:', COMPLEX_MOVEMENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9015fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 256, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploring the observation space\n",
    "\n",
    "env.observation_space.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d649d0",
   "metadata": {},
   "source": [
    "So, we have each frame being 240 $\\times$ 256 pixels with 3 channnels (RBG).\n",
    "\n",
    "Let's choose the simple movements for ease of training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3505e1f9",
   "metadata": {},
   "source": [
    "## Random Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "99298cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking random actions\n",
    "\n",
    "def random_actions(game, movement, num_actions, render):\n",
    "    \n",
    "    \"\"\"\n",
    "    game is the game name.\n",
    "    movements is the type of movement where there are options. 'None' will skip this.\n",
    "    num_actions is the number of steps.\n",
    "    render determines if the game will be displayed, determined with True\n",
    "    \"\"\"\n",
    "    rewards = []\n",
    "    done = True\n",
    "    env = gym_super_mario_bros.make(game)\n",
    "    if movement != 'None':\n",
    "        env = JoypadSpace(env, movement)\n",
    "\n",
    "    # Loop through each frame in the game\n",
    "    for step in range(num_actions): \n",
    "        # Start the game to begin with \n",
    "        if done == True: \n",
    "            env.reset()\n",
    "        # Do random actions\n",
    "        state, reward, done, info = env.step(env.action_space.sample())\n",
    "        if render == True:\n",
    "            env.render()\n",
    "        rewards.append(reward)\n",
    "         \n",
    "    # Close the game and return the rewards\n",
    "    env.close()\n",
    "    return np.sum(rewards)\n",
    "    \n",
    "    # Close the game\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cbb368b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reward in this trajectory is: 503\n"
     ]
    }
   ],
   "source": [
    "print('The reward in this trajectory is:', random_actions('SuperMarioBros-v0', SIMPLE_MOVEMENT, 1000, True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9d8ed0",
   "metadata": {},
   "source": [
    "# Preprocessing the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "734622bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing wrappers\n",
    "\n",
    "# Frame Stacker Wrapper and GrayScaling Wrapper\n",
    "from gym.wrappers import GrayScaleObservation\n",
    "from stable_baselines3.common.vec_env import VecFrameStack, DummyVecEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2660b2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_up_env(game, movement, grayscale, frame_stacking, frames, order):\n",
    "\n",
    "    env = gym_super_mario_bros.make(game)\n",
    "    env = JoypadSpace(env, movement)\n",
    "    if grayscale == True:\n",
    "        env = GrayScaleObservation(env, keep_dim=True)\n",
    "    env = DummyVecEnv([lambda: env])\n",
    "    if frame_stacking == True:\n",
    "        env = VecFrameStack(env, frames, channels_order=order)\n",
    "        \n",
    "    return env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07321e71",
   "metadata": {},
   "source": [
    "### Exploring what the GrayScaleObservation and VecFrameStack do"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a76a30",
   "metadata": {},
   "source": [
    "#### VecFrameStack and GrayScaleObservation turned off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e07e582b",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = set_up_env('SuperMarioBros-v0', SIMPLE_MOVEMENT, False, False, 4, 'last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a2b4d4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State Shape (1, 240, 256, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "state = env.reset()\n",
    "print('State Shape', state.shape)\n",
    "plt.imshow(state[0]).origin='upper'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae790b4",
   "metadata": {},
   "source": [
    "#### GrayScaleObservation Off and VecFrameStack On"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9a6797fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = set_up_env('SuperMarioBros-v0', SIMPLE_MOVEMENT, False, True, 4, 'last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6bd55a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State Shape (1, 240, 256, 12)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "state = env.reset()\n",
    "print('State Shape', state.shape)\n",
    "for i in range(0,4): # Filling our vector with images\n",
    "    state, reward, done, info = env.step([env.action_space.sample()]) # Note that the brackets around the env.action... are\n",
    "# because we have wrapped it\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "for idx in range(12): # So there'll be 4 images with 3 channels\n",
    "    plt.subplot(1,12,idx+1)\n",
    "    plt.imshow(state[0][:,:,idx]).origin='upper' # idx is in ranging through 1-4\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a822790e",
   "metadata": {},
   "source": [
    "#### GrayScaleObservation and VecFrameStack On"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "54690f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = set_up_env('SuperMarioBros-v0', SIMPLE_MOVEMENT, True, True, 4, 'last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "73da04b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State Shape (1, 240, 256, 4)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "state = env.reset()\n",
    "print('State Shape', state.shape)\n",
    "for i in range(0,4): # Filling our vector with images\n",
    "    state, reward, done, info = env.step([env.action_space.sample()]) # Note that the brackets around the env.action... are\n",
    "# because we have wrapped it\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "for idx in range(state.shape[3]): # So there'll be 4 images\n",
    "    plt.subplot(1,4,idx+1)\n",
    "    plt.imshow(state[0][:,:,idx]).origin='upper' # idx is in ranging through 1-4\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06669b1c",
   "metadata": {},
   "source": [
    "## Setting up the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc17a585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7803dfa",
   "metadata": {},
   "source": [
    "# Setting up our agent to be trained with REINFORCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b70885b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State Shape: (240, 256, 4)\n",
      "Number of actions: 7\n"
     ]
    }
   ],
   "source": [
    "# Getting the observation and action shape for our neural net\n",
    "\n",
    "state_shape, n_actions = env.observation_space.shape, env.action_space.n\n",
    "state_dim = state_shape\n",
    "print('State Shape:', state_dim)\n",
    "print('Number of actions:',n_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a254d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAgent(nn.Module):\n",
    "    def __init__(self, state_shape, n_actions):\n",
    "        super().__init__()\n",
    "        self.n_actions = n_actions\n",
    "        self.state_shape = state_shape\n",
    "        \n",
    "        self.conv = nn.Sequential(nn.Conv2d(in_channels=4, out_channels=32, kernel_size=8, stride=4),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2, padding=0),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=8, stride=4),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2, padding=0),\n",
    "            nn.Flatten())\n",
    "        self.fc = nn.Sequential(nn.Linear(288, n_actions))\n",
    "        \n",
    "    def forward(self, state_t):\n",
    "        x = self.conv(state_t)\n",
    "        x= self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "590fd52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = RAgent(state_shape, n_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5784d2",
   "metadata": {},
   "source": [
    "# Trajectory Calculations\n",
    "\n",
    "We will use this function to generate the trajectory. It will not be used for doing back propagation. So we will use PyTorch `no_grad()` to avoid gradient calculations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad1b344",
   "metadata": {},
   "source": [
    "## Generating Trajectory from Action Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "940658f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_probs(states):\n",
    "    \"\"\"\n",
    "    params: states: [batch, state_dim]\n",
    "    Feeds into agent and returns probs: [batch, n_actions]\n",
    "    \"\"\"\n",
    "    states = torch.tensor(states, device=device, dtype=torch.float32)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        # Reshaping and rearranging the states\n",
    "        states = torch.squeeze(states)\n",
    "        states = states.transpose(0,2)\n",
    "        states = states.transpose(1,2)\n",
    "        states = states.unsqueeze(0)\n",
    "        \n",
    "        # Passing the states through the neural net for the logits\n",
    "        logits = agent(states)\n",
    "    probs = nn.functional.softmax(logits, -1).detach().numpy()\n",
    "    \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7baffe71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trajectory(env, n_steps=6):\n",
    "    \"\"\"\n",
    "    Play a session and generate a trajectory of n_steps one step at a time\n",
    "    returns: arrays of states, actions, rewards\n",
    "    \"\"\"\n",
    "    states, actions, rewards = [], [], []\n",
    "    \n",
    "    # Initialize the environment\n",
    "    s = env.reset()\n",
    "    \n",
    "    # Generate n_steps of trajectory:\n",
    "    for t in range(n_steps):\n",
    "        action_probs = predict_probs(np.array([s]))[0]\n",
    "        \n",
    "        # Sample action based on action_probs\n",
    "        a = [np.random.choice(n_actions, p=action_probs)]\n",
    "\n",
    "        next_state, r, done, _ = env.step(a)\n",
    "        \n",
    "        # Update arrays\n",
    "        states.append(s)\n",
    "        actions.append(a)\n",
    "        rewards.append(r)\n",
    "        \n",
    "        s = next_state\n",
    "        if done:\n",
    "            break\n",
    "    return states, actions, rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80c6181",
   "metadata": {},
   "source": [
    "## Calculate Rewards to Go\n",
    "\n",
    " $Q_t ^i = \\sum_{t'=t}^{T} \\gamma^{t-t'} r_{t'+1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f7d2d061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rewards_to_go(rewards, gamma=0.99):\n",
    "    \n",
    "    T = len(rewards) # Total number of individual rewards\n",
    "    # Empty array to return the rewards to go\n",
    "    rewards_to_go = [0]*T \n",
    "    rewards_to_go[T-1] = rewards[T-1]\n",
    "    \n",
    "    for i in range(T-2, -1, -1): # Go from T-2 to 0\n",
    "        rewards_to_go[i] = gamma * rewards_to_go[i+1] + rewards[i]\n",
    "    \n",
    "    return rewards_to_go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e48807",
   "metadata": {},
   "source": [
    "# REINFORCE Training\n",
    "\n",
    "We will calculate the loss and take a gradient step. We will use Adam Optimizer\n",
    "\n",
    "We are taking only one trajectory. so N=1. We will however, average it over the number of actions to get the average loss. So the function we will actually implement is as given below:\n",
    "\n",
    "$$Loss(\\theta) = - J(\\theta) - H(\\mathcal{A}) = - \\frac{1}{T} \\left[ \\sum_{t=1}^{T} \\log{ \\pi(a_t^i|s_t^i,\\mathbf{\\theta})}  Q_t ^i - \\beta \\sum_{a \\in \\mathcal{A}} \\pi(a|s_t^i,\\mathbf{\\theta})\\log{ \\pi(a|s_t^i,\\mathbf{\\theta})} \\right] $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639b8513",
   "metadata": {},
   "source": [
    "## Redefining our environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "93abbed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = set_up_env('SuperMarioBros-v0', SIMPLE_MOVEMENT, True, True, 4, 'last')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acce071",
   "metadata": {},
   "source": [
    "## Single trajectory training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3c1fe02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training over one trajectory\n",
    "\n",
    "# Intializing the optimizer\n",
    "optimizer = torch.optim.Adam(agent.parameters(), lr=1e-3)\n",
    "\n",
    "def train_one_trajectory(states, actions, rewards, gamma=0.99, entropy_coef=1e-2):\n",
    "    \n",
    "    # Get rewards to go\n",
    "    rewards_to_go = get_rewards_to_go(rewards, gamma)\n",
    "\n",
    "    # Convert numpy array to torch tensors\n",
    "    states = torch.tensor(states, device=device, dtype=torch.float)\n",
    "    actions = torch.tensor(actions, device=device, dtype=torch.long)\n",
    "    rewards_to_go = torch.tensor(rewards_to_go, device=device, dtype=torch.float)\n",
    "\n",
    "    # Get action probabilities from states\n",
    "    logits = agent(states) # Get's logits for the possible actions in each state/step of the trajectory. \n",
    "    # Has shape [n_steps, n_actions_per_state]\n",
    "    probs = nn.functional.softmax(logits, -1) # Get's probabilities for the possible actions in each state/step of the\n",
    "    # trajectory. Has shape [n_steps, n_actions_per_state]\n",
    "    log_probs = nn.functional.log_softmax(logits, -1) # Get's log probabilities for the \n",
    "    # possible actions in each state/step of the trajectory. Has shape [n_steps, n_actions_per_state]\n",
    "    \n",
    "    log_probs_for_actions = log_probs[range(len(actions)), actions] # Log probabilities for the actions it ACTUALLY took.\n",
    "    # Has size [n_steps, n_steps]\n",
    "    \n",
    "    # Compute loss to be minimized\n",
    "    J = torch.mean(log_probs_for_actions*rewards_to_go) # Multiplies each log probability for the action ACTUALLY\n",
    "    # taken at step t the Rewards to Go from that step, then divides by the number of trajectories. Produces a single number\n",
    "    H = -(probs*log_probs).sum(-1).mean() # Multiplies each action's probability by its log probability in each step,\n",
    "    # sums them across each step, and then divides by the number of steps. Produces a single number\n",
    "    \n",
    "    loss = -(J+entropy_coef*H)\n",
    "\n",
    "    # Updating the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return np.sum(rewards) # To show progress in training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca7ebe4",
   "metadata": {},
   "source": [
    "## Train the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1a2a2031",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def reinforce_training(iterations):\n",
    "    \n",
    "    total_rewards = []\n",
    "    for i in range(iterations):\n",
    "        print('Step', i)\n",
    "        states, actions, rewards = generate_trajectory(env)    \n",
    "        states = torch.tensor(states).squeeze()\n",
    "        states = states.transpose(1,3)\n",
    "        states = states.transpose(2,3)\n",
    "        reward = train_one_trajectory(states, actions, rewards)\n",
    "        total_rewards.append(reward)\n",
    "        print('Reward this loop:', total_rewards[-1])\n",
    "    env.close()\n",
    "    print('List of rewards', total_rewards)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a5699d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the loop\n",
    "\n",
    "start = time.time()\n",
    "reinforce_training(10)\n",
    "end = time.time()\n",
    "print('The training took', round(end-start,3), 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec545ba",
   "metadata": {},
   "source": [
    "# Evaluation of the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d8d27f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_mario(n_steps, render):\n",
    "\n",
    "    rewards = []\n",
    "    \n",
    "    # Initialize the environment\n",
    "    env = set_up_env('SuperMarioBros-v0', SIMPLE_MOVEMENT, True, True, 4, 'last')\n",
    "    s = env.reset()\n",
    "    \n",
    "    # Generate n_steps of trajectory:\n",
    "    for t in range(n_steps):\n",
    "        action_probs = predict_probs(np.array([s]))[0]\n",
    "        \n",
    "        # Sample action based on action_probs\n",
    "        a = [np.random.choice(n_actions, p=action_probs)]\n",
    "\n",
    "        next_state, r, done, _ = env.step(a)\n",
    "        if render == True:\n",
    "            env.render()\n",
    "\n",
    "        rewards.append(r)\n",
    "        \n",
    "        s = next_state\n",
    "        if done:\n",
    "            break\n",
    "    env.close()\n",
    "\n",
    "    return np.sum(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "411201d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The agent recieved a total reward in one playthrough of 1706.0\n"
     ]
    }
   ],
   "source": [
    "print('The agent recieved a total reward in one playthrough of', evaluate_mario(1000, True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0952774d",
   "metadata": {},
   "source": [
    "# Saving and Reloading the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "824c7345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Saving an agent\n",
    "\n",
    "# torch.save(agent, 'Models/REINFORCE.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b50498a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RAgent(\n",
       "  (conv): Sequential(\n",
       "    (0): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))\n",
       "    (1): Tanh()\n",
       "    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (3): Conv2d(32, 32, kernel_size=(8, 8), stride=(4, 4))\n",
       "    (4): Tanh()\n",
       "    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (6): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=288, out_features=7, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading an agent\n",
    "\n",
    "agent = torch.load('Models/REINFORCE_Best.h5')\n",
    "\n",
    "# Confirming it has the architecture we want\n",
    "agent.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
