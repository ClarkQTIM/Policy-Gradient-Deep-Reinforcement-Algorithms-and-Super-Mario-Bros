{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2b93fc2",
   "metadata": {},
   "source": [
    "# Setting up our Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a926da3c",
   "metadata": {},
   "source": [
    "In this notebook, the setup and exploration of the environment heavily follows Nicholas Renotte's YouTube tutorial *Build an Mario AI Model with Python | Gaming Reinforcement Learning* at: https://www.youtube.com/watch?v=2eeYqJ0uBKE&t=1982s\n",
    "\n",
    "Pertinent Links:\n",
    "\n",
    "Super Mario RL: https://pypi.org/project/gym-super-mario-bros/\n",
    "\n",
    "Nes Py: https://pypi.org/project/nes-py/\n",
    "\n",
    "OpenAI Gym: https://gym.openai.com/\n",
    "\n",
    "Stable Baselines 3: https://stable-baselines3.readthedocs.io/en/master/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a9d763e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Imports\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn_image as isns\n",
    "\n",
    "# Stable Baselines and Logging\n",
    "# Import os for file path management\n",
    "import os \n",
    "# Import PPO for algos\n",
    "from stable_baselines3 import PPO\n",
    "# Import Base Callback for saving models\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "# Misc\n",
    "import time\n",
    "from PIL import Image\n",
    "\n",
    "# from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5435f582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the game\n",
    "import gym_super_mario_bros\n",
    "\n",
    "# Import the Joypad wrapper\n",
    "from nes_py.wrappers import JoypadSpace # Needed for changing the action space\n",
    "\n",
    "# Import the SIMPLIFIED controls\n",
    "from gym_super_mario_bros.actions import RIGHT_ONLY, SIMPLE_MOVEMENT, COMPLEX_MOVEMENT\n",
    "\n",
    "# Misc\n",
    "from gym.spaces import Box\n",
    "from gym.wrappers import FrameStack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d75a6e1",
   "metadata": {},
   "source": [
    "# Trust Region and Proximal Policy Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c60f16a",
   "metadata": {},
   "source": [
    "## Basic Overview of Policy Gradient Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b536bff",
   "metadata": {},
   "source": [
    "The REINFORCE algorithm starts from the concept of a trajectory, $\\large \\tau$, generated by an agent taking actions in states according to some policy parameterized (and therefore, an estimate) by $\\mathbf{\\theta}$:\n",
    "$$a \\approx \\hat{\\pi}(s, \\mathbf{\\theta})$$\n",
    "\n",
    "This action could be discrete, as in this script, in which case the output of $\\hat{\\pi}(s, \\mathbf{\\theta})$ is then a *Categorical Distribution* and the action must then be *sampled*, or, in the continuous case, a $d$-dimensional multivariate normal distribution.\n",
    "\n",
    "The agent follows the policy and generates the trajectory $\\large \\tau$: \n",
    "\n",
    "$$ s_1 \\rightarrow a_1 \\rightarrow s_2 \\rightarrow a_2 \\rightarrow .... \\rightarrow s_{T-1} \\rightarrow a_{T-1} \\rightarrow s_T \\rightarrow a_T$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29952383",
   "metadata": {},
   "source": [
    "The probability of trajectory $\\large \\tau$ depends on the transition probabilities $p(s_t+1 | s_t, a_t)$ and the policy $\\hat{\\pi}(s, \\mathbf{\\theta})$. It is given by the expression:\n",
    "\n",
    "$$p_\\theta(\\tau) = p_\\theta(s_1, a_1, s_2, a_2, ..., s_T, a_T) = p(s_1)\\prod_{t=1}^{T}\\hat{\\pi}(a_t|s_t,\\mathbf{\\theta})p(s_{t+1}|s_t,a_t)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9c0c6e",
   "metadata": {},
   "source": [
    "The expected return from following the policy $\\pi$ is given by:\n",
    "\n",
    "$$J(\\theta) = \\mathbf{E}_{\\tau \\sim p_\\mathbf{\\theta}(\\tau)} \\left[ \\sum_{t=1}^{T} \\gamma^{t-1} r_{t+1} \\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a4ef6f",
   "metadata": {},
   "source": [
    "After some mathematical manipulation, we can calculate $\\nabla_{\\theta} J(\\theta)$ as:\n",
    "\n",
    "$$\\nabla_{\\theta} J(\\theta) =  \\mathbf{E}_{\\tau \\sim p_\\theta(\\tau)} \\left[ \\left( \\sum_{t=1}^{T} \\nabla_{\\theta} \\log{ \\hat{\\pi}(a_t|s_t,\\mathbf{\\theta})} \\right) \\left( \\sum_{t=1}^{T} \\gamma^{t-1} r_{t+1} \\right) \\right] $$\n",
    "\n",
    "We can now replace the outer expectation with an estimate over multiple trajectories to get the following expression for the gradient of policy objective:\n",
    "\n",
    "$$\\nabla_{\\theta} J(\\theta) \\approx  \\frac{1}{N} \\sum_{i=1}^{N} \\left[ \\left( \\sum_{t=1}^{T} \\nabla_{\\theta} \\log{ \\hat{\\pi}_\\theta(a_t^i|s_t^i,\\mathbf{\\theta})} \\right) \\left( \\sum_{t=1}^{T} \\gamma^{t-1} r_{t+1} \\right) \\right] $$\n",
    "\n",
    "where i denotes the $i^{th}$ trajectory. \n",
    "\n",
    "Finally, we will use *Gradient Ascent*, as opposed to the normal *Descent*:\n",
    "\n",
    "$$\\mathbf{\\theta}_{k+1}=\\mathbf{\\theta}_k+\\eta \\nabla _{\\mathbf{\\theta}_k} J(\\mathbf{\\theta}_k)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5b59aa",
   "metadata": {},
   "source": [
    "## Rewards to Go Trick\n",
    "\n",
    "\n",
    "We drop the reward terms that came before time t as at time t, the action we take can only impact the reward which comes at time t and later. This leads to changing the 2nd inner sum going from $t’=t$ to $T$ instead of earlier sum over $t’$ going from $t’=1$ to $T$. i.e. the start index is now $t’=t$ and not $t=1$. The revised expression is given below:\n",
    "\n",
    "\n",
    "$$\\nabla_{\\theta} J(\\theta) \\approx  \\frac{1}{N} \\sum_{i=1}^{N} \\left[  \\sum_{t=1}^{T}  \\left( \\nabla_{\\theta} \\log{ \\hat{\\pi}(a_t^i|s_t^i, \\mathbf{\\theta})} \\right) \\left( \\sum_{t'=t}^{T} \\gamma^{t'-t} r_{t'+1}^i \\right) \\right] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b5240a",
   "metadata": {},
   "source": [
    "However, we note that $\\sum_{t'=t}^{T} \\gamma^{t'-t} r_{t'+1}^i$ is just the Q-value of the state and action at time $t'=t$, so we can replace it with $Q_t ^i = \\sum_{t'=t}^{T} \\gamma^{t'-t} r_{t'+1}^i$. We now have:\n",
    "\n",
    "$$\\nabla_{\\theta} J(\\theta) \\approx  \\frac{1}{N} \\sum_{i=1}^{N} \\left[\\sum_{t=1}^{T}   \\nabla_{\\theta} \\log{ \\hat{\\pi}(a_t^i|s_t^i, \\mathbf{\\theta})} Q_t ^i \\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16db209",
   "metadata": {},
   "source": [
    "## Concepts Required for Trust Region/Proximal Policy Optimization Not Yet Introduced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ac54fc",
   "metadata": {},
   "source": [
    "###  Parameter Space versus Probability Space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d8bb0f",
   "metadata": {},
   "source": [
    "We note that the following update equation:\n",
    "\n",
    "$$\\mathbf{\\theta}_{k+1}=\\mathbf{\\theta}_k+\\eta \\nabla _{\\mathbf{\\theta}_k} J(\\mathbf{\\theta}_k)$$\n",
    "\n",
    "takes a step in *parameter space*. However, we might ask, since the parameters are altering a probability distribution, how do we know if a small step in parameter space is a comparatively small space in probability space? We need a way ot compare the \"distance\" in probability space. To do so, we will introduce the *Kullback-Leiber Divergence*, denoted KL-divergence. Given two distributions, the discrete KL-divergence is:\n",
    "\n",
    "$$ D_{KL}(P||Q) = \\sum_{x} P(x) \\log \\frac{P(x)}{Q(x)} $$\n",
    "\n",
    "The continuous case is:\n",
    "\n",
    "$$ D_{KL}(P||Q) = \\int P(x) \\log \\frac{P(x)}{Q(x)} dx $$\n",
    "\n",
    "Since our probability distributions rely on both the parameters $\\mathbf{\\theta}$ *and* a state *s*, we will write this as:\n",
    "\n",
    "$$ D_{KL} (\\theta_{k+1} || \\theta_k)[s] = \\sum_{a \\in \\mathcal{A}} \\hat{\\pi}(a | s, \\theta_{k+1})\n",
    "\\log \\frac{\\hat{\\pi}(a | s, \\theta_c)} {\\hat{\\pi} (a | s, \\theta_k)}$$\n",
    "\n",
    "We will be interested in the *average* KL-divergence, and we will denote $\\theta_c$ as a candidate parameter set we might update to, giving us:\n",
    "\n",
    "$$ \\bar{D}_{KL} (\\theta_c || \\theta_k )= \n",
    "\\mathbf{E}_{s \\sim \\hat{\\pi}_{\\theta_k}} \\left[ D_{KL} (\\theta_c || \\theta_k)[s] \\right]$$\n",
    "\n",
    "We can then write it in Monte Carlo simulation form as:\n",
    "\n",
    "$$ \\bar{D}_{KL} (\\theta_c || \\theta_k )= \n",
    "\\mathbf{E}_{s \\sim \\hat{\\pi}_{\\theta_k}} \\left[ D_{KL} (\\theta_c || \\theta_k)[s] \\right] =\n",
    "\\frac{1}{NT}\\sum_{i=1}^{N} \\left[ \\sum_{t=1}^{T} \\left[\\sum_{a \\in \\mathcal{A}} \\hat{\\pi}(a | s^i _t, \\theta_{k+1})\n",
    "\\log \\frac{\\hat{\\pi}(a | s^i _t, \\theta_c)} {\\hat{\\pi} (a | s^i _t, \\theta_k)} \\right] \\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a241fb4",
   "metadata": {},
   "source": [
    "### Importance Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5360cfeb",
   "metadata": {},
   "source": [
    "*Importance Sampling* is a technique for estimating expectations using samples drawn from a different distribution. It is defined as:\n",
    "\n",
    "$$ \\mathbf{E}_{x \\sim P} \\left[f(x) \\right] = \\mathbf{E}_{x \\sim Q} \\left[\\frac{P(x)}{Q(x)} f(x) \\right] \\approx \\frac{1}{D} \\sum_{x \\in D} \\frac{P(x)}{Q(x)} f(x) $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9cecf8",
   "metadata": {},
   "source": [
    "### Comparing two policies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17e0266",
   "metadata": {},
   "source": [
    "We will reiterate the basic objective function in policy gradient algorithms, which we seek to maximize:\n",
    "\n",
    "$$J(\\theta) = J(\\theta)_{expected} = \\mathbf{E}_{\\tau \\sim p_\\mathbf{\\theta}(\\tau)} \\left[ \\sum_{t=1}^{T} \\gamma^{t-1} r_{t+1} \\right]$$\n",
    "\n",
    "Now, we can ask, given a policy with parameters $\\theta_k$ and a candidate (for updating) policy with parameters $\\theta_c$, how can we compare them? We will use the following:\n",
    "\n",
    "$$J(\\theta_c) = J(\\theta_k) + \\mathbf{E}_{\\tau \\sim p_\\mathbf{\\theta_c}(\\tau)} \\left[ \\sum_{t=1}^{T} \\gamma^{t-1} A(s_t, a_t, \\theta_k) \\right]$$\n",
    "\n",
    "Thus, we can write an objective function in terms of both policies as:\n",
    "\n",
    "$$ J(\\theta_c) - J(\\theta_k) = J(\\theta_c, \\theta_k) = \\mathbf{E}_{\\tau \\sim p_\\mathbf{\\theta_c}(\\tau)} \\left[ \\sum_{t=1}^{T} \\gamma^{t-1} A(s_t, a_t, \\theta_k) \\right] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61146620",
   "metadata": {},
   "source": [
    "However, we have a problem, namely that our trajectory $\\tau$ is being sampled from a policy *we do not have*. We will briefly describe how to handle this. \n",
    "\n",
    "First, we will decompose the trajectory into actions sampled from a policy with parameters $\\theta_c$ and states sampled from *Discounted Future State Distribution*, defined as:\n",
    "\n",
    "$$ \\rho_{\\theta} (s) = p(s_1 = s)+ \\gamma p(s_2 = s)+ \\gamma^2 p(s_3 = s) + ... = \\sum_{t=1}^{\\infty} \\gamma^{t-1}p(s_t = s) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81c48a5",
   "metadata": {},
   "source": [
    "Now, we can use importance sampling to change the action from being sampled from a policy with parameters $\\theta_c$ to parameters $\\theta_k$ by adding the fraction above.\n",
    "\n",
    "Then, we can make an assumption that $\\rho_{\\theta_c} \\approx \\rho_{\\theta_k}$, which will be true so long as the following holds:\n",
    "\n",
    "$$ J(\\theta_c)-J(\\theta_k) \\geq J(\\theta_c, \\theta_k) - C\\sqrt{\\bar{D}_{KL} (\\theta_c || \\theta_k)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0c2c40",
   "metadata": {},
   "source": [
    "Combining our action and state back into a trajectory, we get:\n",
    "\n",
    "$$J(\\theta_c, \\theta_k) = \\mathbf{E}_{\\tau \\sim \\hat{\\pi}_{\\theta_k}}\n",
    "\\left[\n",
    "\\sum_{t=1}^T \\frac{\\hat{\\pi}(a_t |s_t, \\theta_c)}{\\hat{\\pi}(a_t | s_t, \\theta_k)} A(s_t, a_t, \\theta_k) \\right] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2cf609",
   "metadata": {},
   "source": [
    "## Statement of Trust Region Policy Optimization Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a8fa17",
   "metadata": {},
   "source": [
    "Now, we state our algorithm:\n",
    "\n",
    "$$ \\theta_{k+1} = max_{\\theta_c}J(\\theta_c || \\theta_k)$$\n",
    "\n",
    "Such that:\n",
    "\n",
    "$$J(\\theta_c, \\theta_k) = \\mathbf{E}_{\\tau \\sim \\hat{\\pi}_{\\theta_k}}\n",
    "\\left[\n",
    "\\sum_{t=1}^T \\frac{\\hat{\\pi}(a_t |s_t, \\theta_c)}{\\hat{\\pi}(a_t | s_t, \\theta_k)} A(s_t, a_t, \\theta_k) \\right] $$\n",
    "\n",
    "and:\n",
    "\n",
    "$$ \\bar{D}_{KL}(\\theta_c || \\theta_k) \\leq \\delta $$\n",
    "\n",
    "The way to interpret this is that we want to step in a direction in parameters space with the biggest improvement in policy with the caveat that our step in probability space not be too big. This $\\delta$ is the *Trust REgion*, hence the name of the polcy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8012578c",
   "metadata": {},
   "source": [
    "### Approximations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e54f3b",
   "metadata": {},
   "source": [
    "Unfortunately, this is actually a bit difficult, so we will make some approximations.\n",
    "\n",
    "First, we define:\n",
    "\n",
    "$$ g = \\nabla_{\\theta_k} J(\\theta_k, \\theta_k) $$\n",
    "\n",
    "Then, our first-order Taylor approximation to our objective function is:\n",
    "\n",
    "$$ J(\\theta_c, \\theta_k) \\approx g^T(\\theta_c - \\theta_k) $$\n",
    "\n",
    "By happy coincidence, $g$ simplfies to our regular policy gradient equation:\n",
    "\n",
    "$$ g = \\nabla_{\\theta_k} J(\\theta_k, \\theta_k) =\n",
    "\\mathbf{E}_{\\tau \\sim \\hat{\\pi}_{\\theta_k}} \\left[ \\left( \\sum_{t=1}^{T} \\nabla_{\\theta} \\log{ \\hat{\\pi}(a_t|s_t,\\mathbf{\\theta_k})} \\right) A(s^i _t, a^i _t, \\theta_k) \\right] \\approx \\frac{1}{N} \\sum_{i=1}^{N} \\left[ \\sum_{t=1}^{T}   \\nabla_{\\theta_k} \\log{ \\hat{\\pi}(a_t^i|s_t^i, \\mathbf{\\theta})} A(s^i _t, a^i _t, \\theta_k) \\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adae85c",
   "metadata": {},
   "source": [
    "Then, we will approximate $\\bar{D}_{KL}(\\theta_c || \\theta_k)$ by:\n",
    "\n",
    "$$ \\bar{D}_{KL}(\\theta_c || \\theta_k) \\approx \\frac{1}{2} (\\theta_c - \\theta_k)^T H (\\theta_c - \\theta_k) $$\n",
    "\n",
    "Where:\n",
    "\n",
    "$$ H = \\nabla^2 _{\\theta_k} \\bar{D}_{KL}(\\theta_c || \\theta_k) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c855e63",
   "metadata": {},
   "source": [
    "Our update rule *would* then be:\n",
    "\n",
    "$$ \\theta_{k+1} = \\theta_k + \\sqrt{\\frac{2\\delta}{g^T H^{-1} g}} H^{-1}g $$\n",
    "\n",
    "However, to deal with the possibility that our approximations have introduced problems, we will use:\n",
    "\n",
    "$$ \\theta_{k+1} = \\theta_k + \\alpha^j \\sqrt{\\frac{2\\delta}{g^T H^{-1} g}} H^{-1}g $$\n",
    "\n",
    "Where $\\alpha \\in (0,1)$ and $j$ is the smallest nonnegative integer such that $\\hat{\\pi}(s, \\theta_{k+1})$ satisfies the KL-divergence constraint and gives an actual improvement to our policy.\n",
    "\n",
    "Finally, due the large computational cost of calculating $H$, we will approximate *that* by $Hx=g$. This gives us:\n",
    "\n",
    "$$ \\theta_{k+1} = \\theta_k + \\alpha^j \\sqrt{\\frac{2\\delta}{x^T H^{-1} x}} x $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0654a3",
   "metadata": {},
   "source": [
    "## Statement of Proximal Policy Optimization (Clipped Version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8508e97b",
   "metadata": {},
   "source": [
    "Now, we state our algorithm:\n",
    "\n",
    "$$ \\theta_{k+1} = max_{\\theta_c}J(\\theta_c || \\theta_k)$$\n",
    "\n",
    "Where:\n",
    "\n",
    "$$ J(\\theta_c, \\theta_k) = \\mathbf{E}_{a,s \\sim \\hat{\\pi}_{\\theta_k}} \n",
    "\\left[ \\min \\left( \\frac{\\hat{\\pi}(a_t |s_t, \\theta_c)}{\\hat{\\pi}(a_t | s_t, \\theta_k)} \\right)\n",
    "A(s_t, a_t, \\theta_k), g(\\epsilon, A(s_t, a_t, \\theta_k)) \\right] $$\n",
    "\n",
    "And:\n",
    "\n",
    "$$ g(\\epsilon, A(s,a, \\theta_k) =\n",
    "\\begin{cases}\n",
    "(1+\\epsilon)A, A\\geq 0\\\\\n",
    "(1-\\epsilon)A, A <0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "This is approximated by:\n",
    "\n",
    "$$ J(\\theta_c , \\theta_k) \\approx \\frac{1}{NT} \\sum_{i=1}^{N} \\left[\\sum_{t=1}^{T} \\min \\left(\\frac{\\hat{\\pi}(a^i _t |s^i _t, \\theta_c)} {\\hat{\\pi}(a^i _t | s^i _t, \\theta_k)}\n",
    "A(s^i _t, a^i _t, \\theta_k), g(\\epsilon, A(s^i _t, a^i _t, \\theta_k)) \\right) \\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4056310f",
   "metadata": {},
   "source": [
    "In either implementation, we would update our parameters in the manner above, but then, given that we are *also* approximating our advantage function, say, with parameters $\\mathbf{\\Theta}$, our loss function is:\n",
    "\n",
    "$$ \\mathcal{L}(\\mathbf{\\Theta}) = \\frac{1}{NT} \\sum_{i=1}^N \\left[ \\sum_{t=1}^T \n",
    "(V(s^i _t, \\mathbf{\\Theta}) - Q^i _t)^2 \\right] $$\n",
    "\n",
    "In the above, $Q_t ^i = \\sum_{t'=t}^{T} \\gamma^{t'-t} r_{t'+1}^i$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3b6f92",
   "metadata": {},
   "source": [
    "In this implementation, we will only be using the Proximal Policy Optimization algorithm, as it is simpler nad has similar results to Trust Region Policy Optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8422e4",
   "metadata": {},
   "source": [
    "# Exploring the game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "960f4c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the game\n",
    "\n",
    "env = gym_super_mario_bros.make('SuperMarioBros-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e18042fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RIGHT_ONLY action space: [['NOOP'], ['right'], ['right', 'A'], ['right', 'B'], ['right', 'A', 'B']]\n",
      "\n",
      "\n",
      "The SIMPLE_ACTION action space: [['NOOP'], ['right'], ['right', 'A'], ['right', 'B'], ['right', 'A', 'B'], ['A'], ['left']]\n",
      "\n",
      "\n",
      "The COMPLEX_ACTION action space: [['NOOP'], ['right'], ['right', 'A'], ['right', 'B'], ['right', 'A', 'B'], ['A'], ['left'], ['left', 'A'], ['left', 'B'], ['left', 'A', 'B'], ['down'], ['up']]\n"
     ]
    }
   ],
   "source": [
    "# Exploring the types of movement\n",
    "\n",
    "print('The RIGHT_ONLY action space:', RIGHT_ONLY)\n",
    "print('\\n')\n",
    "print('The SIMPLE_ACTION action space:', SIMPLE_MOVEMENT)\n",
    "print('\\n')\n",
    "print('The COMPLEX_ACTION action space:', COMPLEX_MOVEMENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9015fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240, 256, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exploring the observation space\n",
    "\n",
    "env.observation_space.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d649d0",
   "metadata": {},
   "source": [
    "So, we have each frame being 240 $\\times$ 256 pixels with 3 channnels (RBG).\n",
    "\n",
    "Let's choose the simple movements for ease of training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3505e1f9",
   "metadata": {},
   "source": [
    "## Random Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99298cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking random actions\n",
    "\n",
    "def random_actions(game, movement, num_actions, render):\n",
    "    \n",
    "    \"\"\"\n",
    "    game is the game name.\n",
    "    movements is the type of movement where there are options. 'None' will skip this.\n",
    "    num_actions is the number of steps.\n",
    "    render determines if the game will be displayed, determined with True\n",
    "    \"\"\"\n",
    "    rewards = []\n",
    "    done = True\n",
    "    env = gym_super_mario_bros.make(game)\n",
    "    if movement != 'None':\n",
    "        env = JoypadSpace(env, movement)\n",
    "\n",
    "    # Loop through each frame in the game\n",
    "    for step in range(num_actions): \n",
    "        # Start the game to begin with \n",
    "        if done == True: \n",
    "            env.reset()\n",
    "        # Do random actions\n",
    "        state, reward, done, info = env.step(env.action_space.sample())\n",
    "        if render == True:\n",
    "            env.render()\n",
    "        rewards.append(reward)\n",
    "         \n",
    "    # Close the game and return the rewards\n",
    "    env.close()\n",
    "    return np.sum(rewards)\n",
    "    \n",
    "    # Close the game\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbb368b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\anaconda3\\lib\\site-packages\\pyglet\\image\\codecs\\wic.py:289: UserWarning: [WinError -2147417850] Cannot change thread mode after it is set\n",
      "  warnings.warn(str(err))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reward in this trajectory is: 504\n"
     ]
    }
   ],
   "source": [
    "print('The reward in this trajectory is:', random_actions('SuperMarioBros-v0', SIMPLE_MOVEMENT, 1000, True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9d8ed0",
   "metadata": {},
   "source": [
    "# Preprocessing the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "734622bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing wrappers\n",
    "\n",
    "# Frame Stacker Wrapper and GrayScaling Wrapper\n",
    "from gym.wrappers import GrayScaleObservation\n",
    "from stable_baselines3.common.vec_env import VecFrameStack, DummyVecEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2660b2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up our environment\n",
    "\n",
    "def set_up_env(game, movement, grayscale, frame_stacking, frames, order):\n",
    "\n",
    "    env = gym_super_mario_bros.make(game)\n",
    "    env = JoypadSpace(env, movement)\n",
    "    if grayscale == True:\n",
    "        env = GrayScaleObservation(env, keep_dim=True)\n",
    "    env = DummyVecEnv([lambda: env])\n",
    "    if frame_stacking == True:\n",
    "        env = VecFrameStack(env, frames, channels_order=order)\n",
    "        \n",
    "    return env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07321e71",
   "metadata": {},
   "source": [
    "## Exploring what the GrayScaleObservation and VecFrameStack do"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a76a30",
   "metadata": {},
   "source": [
    "### VecFrameStack and GrayScaleObservation turned off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e07e582b",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = set_up_env('SuperMarioBros-v0', SIMPLE_MOVEMENT, False, False, 4, 'last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2b4d4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State Shape (1, 240, 256, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "state = env.reset()\n",
    "print('State Shape', state.shape)\n",
    "plt.imshow(state[0]).origin='upper'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae790b4",
   "metadata": {},
   "source": [
    "### GrayScaleObservation Off and VecFrameStack On"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a6797fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = set_up_env('SuperMarioBros-v0', SIMPLE_MOVEMENT, False, True, 4, 'last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bd55a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State Shape (1, 240, 256, 12)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "state = env.reset()\n",
    "print('State Shape', state.shape)\n",
    "for i in range(0,4): # Filling our vector with images\n",
    "    state, reward, done, info = env.step([env.action_space.sample()]) # Note that the brackets around the env.action... are\n",
    "# because we have wrapped it\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "for idx in range(12): # So there'll be 4 images with 3 channels\n",
    "    plt.subplot(1,12,idx+1)\n",
    "    plt.imshow(state[0][:,:,idx]).origin='upper' # idx is in ranging through 1-4\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a822790e",
   "metadata": {},
   "source": [
    "### GrayScaleObservation and VecFrameStack On"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54690f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = set_up_env('SuperMarioBros-v0', SIMPLE_MOVEMENT, True, True, 4, 'last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73da04b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State Shape (1, 240, 256, 4)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "state = env.reset()\n",
    "print('State Shape', state.shape)\n",
    "for i in range(0,4): # Filling our vector with images\n",
    "    state, reward, done, info = env.step([env.action_space.sample()]) # Note that the brackets around the env.action... are\n",
    "# because we have wrapped it\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "for idx in range(state.shape[3]): # So there'll be 4 images\n",
    "    plt.subplot(1,4,idx+1)\n",
    "    plt.imshow(state[0][:,:,idx]).origin='upper' # idx is in ranging through 1-4\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4525e083",
   "metadata": {},
   "source": [
    "# Train the RL Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e519d966",
   "metadata": {},
   "source": [
    "## Setting up the logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b53d785e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training and Logging Callback function\n",
    "\n",
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "\n",
    "    def __init__(self, check_freq, save_path, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b5d8fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = './train/'\n",
    "LOG_DIR = './logs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f96c71d1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup model saving callback\n",
    "\n",
    "check_freq = 10000\n",
    "callback = TrainAndLoggingCallback(check_freq=check_freq, save_path=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77290a85",
   "metadata": {},
   "source": [
    "## Setting up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "648a3367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 240, 256, 4)\n"
     ]
    }
   ],
   "source": [
    "env = set_up_env('SuperMarioBros-v0', SIMPLE_MOVEMENT, True, True, 4, 'last')\n",
    "state = env.reset()\n",
    "print('State shape', state.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401e899b",
   "metadata": {},
   "source": [
    "## Defining and Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e39429",
   "metadata": {},
   "source": [
    "### Setting up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "36232bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PPO Model\n",
    "\n",
    "def PPO_model(policy, env, verbose, log_dir, lr, n_steps):\n",
    "    \"\"\"\n",
    "    policy is a string and can be 'MlpPolicy' or 'CnnPolicy'\n",
    "    n_steps is the number of time-steps in a trajectory\n",
    "    learning_rate is the learning rate for the optimizer, which is Adam by default\n",
    "    \"\"\"\n",
    "    if log_dir == 'None':\n",
    "        model = PPO(policy, env, verbose=verbose, learning_rate=lr, \n",
    "            n_steps=n_steps) \n",
    "    else: \n",
    "        model = PPO(policy, env, verbose=verbose, tensorboard_log=log_dir, learning_rate=lr, \n",
    "            n_steps=n_steps) \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65b3123",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ceea2c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "def model_learning(model, time_steps, callback):\n",
    "    \n",
    "    if callback == 'None':\n",
    "        model.learn(total_timesteps=time_steps)\n",
    "    else:\n",
    "        model.learn(total_timesteps=time_steps, callback = callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7cebdd4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "model = PPO_model('CnnPolicy', env, 1, 'None', 1e-5, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "80fdae58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "| time/              |     |\n",
      "|    fps             | 77  |\n",
      "|    iterations      | 1   |\n",
      "|    time_elapsed    | 6   |\n",
      "|    total_timesteps | 512 |\n",
      "----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 65          |\n",
      "|    total_timesteps      | 1024        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004020581 |\n",
      "|    clip_fraction        | 0.0203      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.94       |\n",
      "|    explained_variance   | -0.000397   |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 42.5        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00328    |\n",
      "|    value_loss           | 176         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 10          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 141         |\n",
      "|    total_timesteps      | 1536        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011384506 |\n",
      "|    clip_fraction        | 0.0291      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.94       |\n",
      "|    explained_variance   | 0.00885     |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 0.13        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0067     |\n",
      "|    value_loss           | 3.93        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 8            |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 228          |\n",
      "|    total_timesteps      | 2048         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024370907 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.93        |\n",
      "|    explained_variance   | -0.0562      |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.246        |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.000575    |\n",
      "|    value_loss           | 1.99         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 8            |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 312          |\n",
      "|    total_timesteps      | 2560         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035183465 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.93        |\n",
      "|    explained_variance   | 0.0617       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.144        |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00182     |\n",
      "|    value_loss           | 1.14         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 7            |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 398          |\n",
      "|    total_timesteps      | 3072         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010085923 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.92        |\n",
      "|    explained_variance   | -0.0538      |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.0937       |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.000222    |\n",
      "|    value_loss           | 1.02         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 7           |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 483         |\n",
      "|    total_timesteps      | 3584        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002038766 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.93       |\n",
      "|    explained_variance   | -0.0512     |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 0.11        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00224    |\n",
      "|    value_loss           | 0.827       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 7            |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 569          |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017546475 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.93        |\n",
      "|    explained_variance   | 0.0564       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.168        |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00133     |\n",
      "|    value_loss           | 0.991        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 7            |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 654          |\n",
      "|    total_timesteps      | 4608         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034757424 |\n",
      "|    clip_fraction        | 0.00254      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.91        |\n",
      "|    explained_variance   | 0.0166       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 13.7         |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | 0.00016      |\n",
      "|    value_loss           | 52.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 6           |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 742         |\n",
      "|    total_timesteps      | 5120        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005488656 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.91       |\n",
      "|    explained_variance   | 0.0728      |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 0.117       |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.003      |\n",
      "|    value_loss           | 0.432       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 6            |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 824          |\n",
      "|    total_timesteps      | 5632         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004591843 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.91        |\n",
      "|    explained_variance   | 0.514        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.142        |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | 0.000283     |\n",
      "|    value_loss           | 0.664        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 6           |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 903         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007920427 |\n",
      "|    clip_fraction        | 0.0643      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.218       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 0.0891      |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00673    |\n",
      "|    value_loss           | 0.351       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 6           |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 983         |\n",
      "|    total_timesteps      | 6656        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005869755 |\n",
      "|    clip_fraction        | 0.000977    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | 0.339       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 0.0384      |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.00347    |\n",
      "|    value_loss           | 0.35        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 6            |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 1068         |\n",
      "|    total_timesteps      | 7168         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028080116 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.9         |\n",
      "|    explained_variance   | 0.187        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.0759       |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00219     |\n",
      "|    value_loss           | 0.301        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 6            |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 1147         |\n",
      "|    total_timesteps      | 7680         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016007122 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.91        |\n",
      "|    explained_variance   | 0.14         |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.0811       |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -7.45e-06    |\n",
      "|    value_loss           | 0.249        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 6            |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 1227         |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013429591 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.9         |\n",
      "|    explained_variance   | 0.552        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.0575       |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.00125     |\n",
      "|    value_loss           | 0.196        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 6           |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 1315        |\n",
      "|    total_timesteps      | 8704        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010479184 |\n",
      "|    clip_fraction        | 0.0207      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.87       |\n",
      "|    explained_variance   | -0.0804     |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 0.0763      |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00432    |\n",
      "|    value_loss           | 0.212       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 6          |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 1398       |\n",
      "|    total_timesteps      | 9216       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03289882 |\n",
      "|    clip_fraction        | 0.32       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.7       |\n",
      "|    explained_variance   | 0.0175     |\n",
      "|    learning_rate        | 1e-05      |\n",
      "|    loss                 | 67.1       |\n",
      "|    n_updates            | 170        |\n",
      "|    policy_gradient_loss | 0.0106     |\n",
      "|    value_loss           | 228        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 6            |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 1482         |\n",
      "|    total_timesteps      | 9728         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070821466 |\n",
      "|    clip_fraction        | 0.0119       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.69        |\n",
      "|    explained_variance   | 0.375        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 5.83         |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -7.57e-05    |\n",
      "|    value_loss           | 37.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 6           |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 1570        |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006243865 |\n",
      "|    clip_fraction        | 0.0154      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.68       |\n",
      "|    explained_variance   | 0.261       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 0.224       |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.00297    |\n",
      "|    value_loss           | 0.556       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 6           |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 1655        |\n",
      "|    total_timesteps      | 10752       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005737233 |\n",
      "|    clip_fraction        | 0.0146      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.69       |\n",
      "|    explained_variance   | -0.0294     |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 0.138       |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00281    |\n",
      "|    value_loss           | 0.494       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 6            |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 1742         |\n",
      "|    total_timesteps      | 11264        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035707275 |\n",
      "|    clip_fraction        | 0.00137      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.7         |\n",
      "|    explained_variance   | 0.00621      |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.131        |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.00175     |\n",
      "|    value_loss           | 0.426        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 6           |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 1826        |\n",
      "|    total_timesteps      | 11776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016526928 |\n",
      "|    clip_fraction        | 0.0543      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | 0.0682      |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 0.114       |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00901    |\n",
      "|    value_loss           | 0.362       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 6           |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 1916        |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013140924 |\n",
      "|    clip_fraction        | 0.0982      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.57       |\n",
      "|    explained_variance   | 0.0153      |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 0.0872      |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00984    |\n",
      "|    value_loss           | 0.336       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 6           |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 2005        |\n",
      "|    total_timesteps      | 12800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018665854 |\n",
      "|    clip_fraction        | 0.0504      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | -0.0034     |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 0.163       |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00691    |\n",
      "|    value_loss           | 0.298       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 6           |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 2095        |\n",
      "|    total_timesteps      | 13312       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009922363 |\n",
      "|    clip_fraction        | 0.0172      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.66       |\n",
      "|    explained_variance   | 0.0114      |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 0.123       |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0063     |\n",
      "|    value_loss           | 0.274       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 6            |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 2187         |\n",
      "|    total_timesteps      | 13824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068440554 |\n",
      "|    clip_fraction        | 0.00371      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.61        |\n",
      "|    explained_variance   | 0.855        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.169        |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    value_loss           | 0.808        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 6          |\n",
      "|    iterations           | 28         |\n",
      "|    time_elapsed         | 2278       |\n",
      "|    total_timesteps      | 14336      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04733637 |\n",
      "|    clip_fraction        | 0.326      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.24      |\n",
      "|    explained_variance   | 0.34       |\n",
      "|    learning_rate        | 1e-05      |\n",
      "|    loss                 | 42         |\n",
      "|    n_updates            | 270        |\n",
      "|    policy_gradient_loss | 0.0144     |\n",
      "|    value_loss           | 205        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 6           |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 2367        |\n",
      "|    total_timesteps      | 14848       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006371394 |\n",
      "|    clip_fraction        | 0.0395      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.31        |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 114         |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.000742   |\n",
      "|    value_loss           | 248         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 6           |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 2461        |\n",
      "|    total_timesteps      | 15360       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010381736 |\n",
      "|    clip_fraction        | 0.0375      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.936      |\n",
      "|    explained_variance   | 0.543       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 49.7        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.00195    |\n",
      "|    value_loss           | 136         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 6            |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 2552         |\n",
      "|    total_timesteps      | 15872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046736165 |\n",
      "|    clip_fraction        | 0.0209       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.85        |\n",
      "|    explained_variance   | 0.219        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 332          |\n",
      "|    n_updates            | 300          |\n",
      "|    policy_gradient_loss | -0.000464    |\n",
      "|    value_loss           | 398          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 6            |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 2641         |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067411754 |\n",
      "|    clip_fraction        | 0.0234       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.782       |\n",
      "|    explained_variance   | 0.0638       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 128          |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | 0.000321     |\n",
      "|    value_loss           | 441          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 6            |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 2729         |\n",
      "|    total_timesteps      | 16896        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0134735815 |\n",
      "|    clip_fraction        | 0.0875       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.681       |\n",
      "|    explained_variance   | 0.464        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 21.5         |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.00629     |\n",
      "|    value_loss           | 111          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 6            |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 2818         |\n",
      "|    total_timesteps      | 17408        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049989615 |\n",
      "|    clip_fraction        | 0.0197       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.564       |\n",
      "|    explained_variance   | 0.575        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 72.9         |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.00186     |\n",
      "|    value_loss           | 179          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 6            |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 2913         |\n",
      "|    total_timesteps      | 17920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037461605 |\n",
      "|    clip_fraction        | 0.0486       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.558       |\n",
      "|    explained_variance   | 0.104        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 216          |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.00467     |\n",
      "|    value_loss           | 436          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 6           |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 3008        |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004833749 |\n",
      "|    clip_fraction        | 0.0201      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.558      |\n",
      "|    explained_variance   | 0.472       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 19.2        |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.00183    |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 6            |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 3104         |\n",
      "|    total_timesteps      | 18944        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017092354 |\n",
      "|    clip_fraction        | 0.0107       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.497       |\n",
      "|    explained_variance   | 0.606        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 59.4         |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.00208     |\n",
      "|    value_loss           | 147          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 6           |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 3206        |\n",
      "|    total_timesteps      | 19456       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005339957 |\n",
      "|    clip_fraction        | 0.049       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.523      |\n",
      "|    explained_variance   | 0.697       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 65.8        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.00384    |\n",
      "|    value_loss           | 170         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 6            |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 3306         |\n",
      "|    total_timesteps      | 19968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054421504 |\n",
      "|    clip_fraction        | 0.0312       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.547       |\n",
      "|    explained_variance   | 0.31         |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 596          |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.00109     |\n",
      "|    value_loss           | 507          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 6            |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 3394         |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016049902 |\n",
      "|    clip_fraction        | 0.0131       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.589       |\n",
      "|    explained_variance   | 0.41         |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 176          |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.00125     |\n",
      "|    value_loss           | 344          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 6            |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 3477         |\n",
      "|    total_timesteps      | 20992        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050939014 |\n",
      "|    clip_fraction        | 0.0504       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.716       |\n",
      "|    explained_variance   | 0.704        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 191          |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -0.00288     |\n",
      "|    value_loss           | 345          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 6            |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 3556         |\n",
      "|    total_timesteps      | 21504        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019980047 |\n",
      "|    clip_fraction        | 0.0572       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.77        |\n",
      "|    explained_variance   | 0.78         |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 271          |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.00388     |\n",
      "|    value_loss           | 325          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 6           |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 3634        |\n",
      "|    total_timesteps      | 22016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008976305 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.816      |\n",
      "|    explained_variance   | 0.766       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 95.2        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.00841    |\n",
      "|    value_loss           | 228         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 6            |\n",
      "|    iterations           | 44           |\n",
      "|    time_elapsed         | 3714         |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075172344 |\n",
      "|    clip_fraction        | 0.0461       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.868       |\n",
      "|    explained_variance   | 0.193        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 24.5         |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.00274     |\n",
      "|    value_loss           | 131          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 6           |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 3792        |\n",
      "|    total_timesteps      | 23040       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009353716 |\n",
      "|    clip_fraction        | 0.0934      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.971      |\n",
      "|    explained_variance   | 0.706       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 68.9        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00433    |\n",
      "|    value_loss           | 223         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 6           |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 3871        |\n",
      "|    total_timesteps      | 23552       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009033326 |\n",
      "|    clip_fraction        | 0.026       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.981      |\n",
      "|    explained_variance   | 0.538       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 95.1        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | 0.000378    |\n",
      "|    value_loss           | 345         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 6           |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 3956        |\n",
      "|    total_timesteps      | 24064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010194099 |\n",
      "|    clip_fraction        | 0.0656      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.551       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 72.2        |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00336    |\n",
      "|    value_loss           | 391         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 6           |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 4034        |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021053713 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.459       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 41.4        |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.00852    |\n",
      "|    value_loss           | 245         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 6          |\n",
      "|    iterations           | 49         |\n",
      "|    time_elapsed         | 4108       |\n",
      "|    total_timesteps      | 25088      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01357297 |\n",
      "|    clip_fraction        | 0.0773     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.05      |\n",
      "|    explained_variance   | 0.668      |\n",
      "|    learning_rate        | 1e-05      |\n",
      "|    loss                 | 226        |\n",
      "|    n_updates            | 480        |\n",
      "|    policy_gradient_loss | -0.00279   |\n",
      "|    value_loss           | 427        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 6          |\n",
      "|    iterations           | 50         |\n",
      "|    time_elapsed         | 4184       |\n",
      "|    total_timesteps      | 25600      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01010878 |\n",
      "|    clip_fraction        | 0.0547     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.06      |\n",
      "|    explained_variance   | 0.604      |\n",
      "|    learning_rate        | 1e-05      |\n",
      "|    loss                 | 143        |\n",
      "|    n_updates            | 490        |\n",
      "|    policy_gradient_loss | -0.00358   |\n",
      "|    value_loss           | 459        |\n",
      "----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 6             |\n",
      "|    iterations           | 51            |\n",
      "|    time_elapsed         | 4257          |\n",
      "|    total_timesteps      | 26112         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00043197058 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.04         |\n",
      "|    explained_variance   | 0.711         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 482           |\n",
      "|    n_updates            | 500           |\n",
      "|    policy_gradient_loss | 6.85e-05      |\n",
      "|    value_loss           | 359           |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 6            |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 4332         |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071943887 |\n",
      "|    clip_fraction        | 0.00488      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0.598        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 200          |\n",
      "|    n_updates            | 510          |\n",
      "|    policy_gradient_loss | -0.00199     |\n",
      "|    value_loss           | 460          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 6           |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 4409        |\n",
      "|    total_timesteps      | 27136       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011173071 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.996      |\n",
      "|    explained_variance   | 0.503       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 166         |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.00752    |\n",
      "|    value_loss           | 506         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 6            |\n",
      "|    iterations           | 54           |\n",
      "|    time_elapsed         | 4490         |\n",
      "|    total_timesteps      | 27648        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007171446 |\n",
      "|    clip_fraction        | 0.00332      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.01        |\n",
      "|    explained_variance   | 0.599        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 82.2         |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | 0.000612     |\n",
      "|    value_loss           | 211          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 6            |\n",
      "|    iterations           | 55           |\n",
      "|    time_elapsed         | 4627         |\n",
      "|    total_timesteps      | 28160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025522993 |\n",
      "|    clip_fraction        | 0.018        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0.804        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 121          |\n",
      "|    n_updates            | 540          |\n",
      "|    policy_gradient_loss | -0.0022      |\n",
      "|    value_loss           | 269          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 6           |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 4762        |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014822309 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.574       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 108         |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.00978    |\n",
      "|    value_loss           | 506         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 5          |\n",
      "|    iterations           | 57         |\n",
      "|    time_elapsed         | 4898       |\n",
      "|    total_timesteps      | 29184      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00294779 |\n",
      "|    clip_fraction        | 0          |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.06      |\n",
      "|    explained_variance   | 0.856      |\n",
      "|    learning_rate        | 1e-05      |\n",
      "|    loss                 | 94.9       |\n",
      "|    n_updates            | 560        |\n",
      "|    policy_gradient_loss | -0.00164   |\n",
      "|    value_loss           | 194        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 5032        |\n",
      "|    total_timesteps      | 29696       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006041765 |\n",
      "|    clip_fraction        | 0.000195    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0.593       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 317         |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.000825   |\n",
      "|    value_loss           | 515         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 5163        |\n",
      "|    total_timesteps      | 30208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007216297 |\n",
      "|    clip_fraction        | 0.0355      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.517       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 106         |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | -0.00217    |\n",
      "|    value_loss           | 299         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 60           |\n",
      "|    time_elapsed         | 5292         |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053012506 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0.465        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 493          |\n",
      "|    n_updates            | 590          |\n",
      "|    policy_gradient_loss | -0.000604    |\n",
      "|    value_loss           | 856          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 61           |\n",
      "|    time_elapsed         | 5420         |\n",
      "|    total_timesteps      | 31232        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034995049 |\n",
      "|    clip_fraction        | 0.00391      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0.803        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 65.4         |\n",
      "|    n_updates            | 600          |\n",
      "|    policy_gradient_loss | -6.11e-05    |\n",
      "|    value_loss           | 175          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 62           |\n",
      "|    time_elapsed         | 5556         |\n",
      "|    total_timesteps      | 31744        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057005286 |\n",
      "|    clip_fraction        | 0.0381       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 0.6          |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 487          |\n",
      "|    n_updates            | 610          |\n",
      "|    policy_gradient_loss | -0.00403     |\n",
      "|    value_loss           | 491          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 5743        |\n",
      "|    total_timesteps      | 32256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009345148 |\n",
      "|    clip_fraction        | 0.00918     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0.538       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 107         |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.000586   |\n",
      "|    value_loss           | 291         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 5939        |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009062216 |\n",
      "|    clip_fraction        | 0.0586      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.615       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 120         |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.00473    |\n",
      "|    value_loss           | 537         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 6120        |\n",
      "|    total_timesteps      | 33280       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003829647 |\n",
      "|    clip_fraction        | 0.0211      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.521       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 126         |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.00231    |\n",
      "|    value_loss           | 290         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 6246        |\n",
      "|    total_timesteps      | 33792       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012624773 |\n",
      "|    clip_fraction        | 0.0379      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.358       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 189         |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.0055     |\n",
      "|    value_loss           | 591         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 6374        |\n",
      "|    total_timesteps      | 34304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020176668 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.989      |\n",
      "|    explained_variance   | 0.552       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 315         |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.00893    |\n",
      "|    value_loss           | 478         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 6496         |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026557301 |\n",
      "|    clip_fraction        | 0.0729       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.916       |\n",
      "|    explained_variance   | 0.255        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 130          |\n",
      "|    n_updates            | 670          |\n",
      "|    policy_gradient_loss | -0.00437     |\n",
      "|    value_loss           | 703          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 5          |\n",
      "|    iterations           | 69         |\n",
      "|    time_elapsed         | 6605       |\n",
      "|    total_timesteps      | 35328      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01857899 |\n",
      "|    clip_fraction        | 0.0598     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.933     |\n",
      "|    explained_variance   | 0.465      |\n",
      "|    learning_rate        | 1e-05      |\n",
      "|    loss                 | 407        |\n",
      "|    n_updates            | 680        |\n",
      "|    policy_gradient_loss | -0.00451   |\n",
      "|    value_loss           | 673        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 6712        |\n",
      "|    total_timesteps      | 35840       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016738253 |\n",
      "|    clip_fraction        | 0.0615      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.872      |\n",
      "|    explained_variance   | 0.681       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 75.9        |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.00234    |\n",
      "|    value_loss           | 246         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 71           |\n",
      "|    time_elapsed         | 6815         |\n",
      "|    total_timesteps      | 36352        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016119275 |\n",
      "|    clip_fraction        | 0.00684      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.791       |\n",
      "|    explained_variance   | 0.756        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 115          |\n",
      "|    n_updates            | 700          |\n",
      "|    policy_gradient_loss | -0.000944    |\n",
      "|    value_loss           | 281          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 6918        |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011339919 |\n",
      "|    clip_fraction        | 0.0262      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.702      |\n",
      "|    explained_variance   | 0.369       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 235         |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.00233    |\n",
      "|    value_loss           | 587         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 7023         |\n",
      "|    total_timesteps      | 37376        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029188236 |\n",
      "|    clip_fraction        | 0.0213       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.667       |\n",
      "|    explained_variance   | 0.734        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 70.7         |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | 0.000105     |\n",
      "|    value_loss           | 170          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 74          |\n",
      "|    time_elapsed         | 7126        |\n",
      "|    total_timesteps      | 37888       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008781251 |\n",
      "|    clip_fraction        | 0.0402      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.652      |\n",
      "|    explained_variance   | 0.369       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 186         |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | -0.00196    |\n",
      "|    value_loss           | 876         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 7226        |\n",
      "|    total_timesteps      | 38400       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003966816 |\n",
      "|    clip_fraction        | 0.0746      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.541      |\n",
      "|    explained_variance   | 0.364       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 342         |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.00455    |\n",
      "|    value_loss           | 588         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 76           |\n",
      "|    time_elapsed         | 7326         |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059044184 |\n",
      "|    clip_fraction        | 0.0496       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.6         |\n",
      "|    explained_variance   | 0.657        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 310          |\n",
      "|    n_updates            | 750          |\n",
      "|    policy_gradient_loss | -0.00213     |\n",
      "|    value_loss           | 572          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 7426        |\n",
      "|    total_timesteps      | 39424       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004006331 |\n",
      "|    clip_fraction        | 0.0559      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.622      |\n",
      "|    explained_variance   | 0.579       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 150         |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.00258    |\n",
      "|    value_loss           | 337         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 78           |\n",
      "|    time_elapsed         | 7524         |\n",
      "|    total_timesteps      | 39936        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030263294 |\n",
      "|    clip_fraction        | 0.0473       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.683       |\n",
      "|    explained_variance   | 0.513        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 482          |\n",
      "|    n_updates            | 770          |\n",
      "|    policy_gradient_loss | -0.00398     |\n",
      "|    value_loss           | 755          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 79           |\n",
      "|    time_elapsed         | 7622         |\n",
      "|    total_timesteps      | 40448        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024335682 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.656       |\n",
      "|    explained_variance   | 0.719        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 133          |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | -5.88e-05    |\n",
      "|    value_loss           | 214          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 7720         |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018136639 |\n",
      "|    clip_fraction        | 0.0209       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.619       |\n",
      "|    explained_variance   | 0.646        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 324          |\n",
      "|    n_updates            | 790          |\n",
      "|    policy_gradient_loss | -0.00474     |\n",
      "|    value_loss           | 626          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 7817        |\n",
      "|    total_timesteps      | 41472       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001494862 |\n",
      "|    clip_fraction        | 0.0156      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.661      |\n",
      "|    explained_variance   | 0.66        |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 88.3        |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.00311    |\n",
      "|    value_loss           | 214         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 7915        |\n",
      "|    total_timesteps      | 41984       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007658264 |\n",
      "|    clip_fraction        | 0.0633      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.659      |\n",
      "|    explained_variance   | 0.785       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 273         |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.00454    |\n",
      "|    value_loss           | 345         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 83           |\n",
      "|    time_elapsed         | 8010         |\n",
      "|    total_timesteps      | 42496        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034745464 |\n",
      "|    clip_fraction        | 0.0193       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.675       |\n",
      "|    explained_variance   | 0.654        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 93.2         |\n",
      "|    n_updates            | 820          |\n",
      "|    policy_gradient_loss | 0.00108      |\n",
      "|    value_loss           | 275          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 8103        |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004919893 |\n",
      "|    clip_fraction        | 0.00918     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.736      |\n",
      "|    explained_variance   | 0.593       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 443         |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.00119    |\n",
      "|    value_loss           | 672         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 8196        |\n",
      "|    total_timesteps      | 43520       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004447839 |\n",
      "|    clip_fraction        | 0.0348      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.739      |\n",
      "|    explained_variance   | 0.553       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 410         |\n",
      "|    n_updates            | 840         |\n",
      "|    policy_gradient_loss | -0.00158    |\n",
      "|    value_loss           | 778         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 86           |\n",
      "|    time_elapsed         | 8287         |\n",
      "|    total_timesteps      | 44032        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010356497 |\n",
      "|    clip_fraction        | 0.0121       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.64        |\n",
      "|    explained_variance   | 0.523        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 83.9         |\n",
      "|    n_updates            | 850          |\n",
      "|    policy_gradient_loss | -0.000364    |\n",
      "|    value_loss           | 248          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 8376        |\n",
      "|    total_timesteps      | 44544       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008346654 |\n",
      "|    clip_fraction        | 0.0705      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.568      |\n",
      "|    explained_variance   | 0.472       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 118         |\n",
      "|    n_updates            | 860         |\n",
      "|    policy_gradient_loss | -0.00176    |\n",
      "|    value_loss           | 591         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 8471        |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006499007 |\n",
      "|    clip_fraction        | 0.0754      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.568      |\n",
      "|    explained_variance   | 0.451       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 128         |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | -0.0032     |\n",
      "|    value_loss           | 657         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 8567        |\n",
      "|    total_timesteps      | 45568       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010852507 |\n",
      "|    clip_fraction        | 0.0973      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.687      |\n",
      "|    explained_variance   | 0.342       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 338         |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.00591    |\n",
      "|    value_loss           | 888         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 8656        |\n",
      "|    total_timesteps      | 46080       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001885303 |\n",
      "|    clip_fraction        | 0.0625      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.748      |\n",
      "|    explained_variance   | 0.566       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 323         |\n",
      "|    n_updates            | 890         |\n",
      "|    policy_gradient_loss | -0.00486    |\n",
      "|    value_loss           | 510         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 8746        |\n",
      "|    total_timesteps      | 46592       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004608738 |\n",
      "|    clip_fraction        | 0.0738      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.882      |\n",
      "|    explained_variance   | 0.761       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 78.6        |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.0035     |\n",
      "|    value_loss           | 199         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 92           |\n",
      "|    time_elapsed         | 8833         |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053574303 |\n",
      "|    clip_fraction        | 0.0678       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.934       |\n",
      "|    explained_variance   | 0.733        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 363          |\n",
      "|    n_updates            | 910          |\n",
      "|    policy_gradient_loss | -0.00219     |\n",
      "|    value_loss           | 767          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 5             |\n",
      "|    iterations           | 93            |\n",
      "|    time_elapsed         | 8922          |\n",
      "|    total_timesteps      | 47616         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00096604414 |\n",
      "|    clip_fraction        | 0.0139        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.882        |\n",
      "|    explained_variance   | 0.498         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 66.4          |\n",
      "|    n_updates            | 920           |\n",
      "|    policy_gradient_loss | -0.000594     |\n",
      "|    value_loss           | 238           |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 9012        |\n",
      "|    total_timesteps      | 48128       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013840232 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.962      |\n",
      "|    explained_variance   | 0.708       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 66.9        |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.00421    |\n",
      "|    value_loss           | 155         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 9101        |\n",
      "|    total_timesteps      | 48640       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012341534 |\n",
      "|    clip_fraction        | 0.0529      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.996      |\n",
      "|    explained_variance   | 0.51        |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 109         |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.00149    |\n",
      "|    value_loss           | 646         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 5          |\n",
      "|    iterations           | 96         |\n",
      "|    time_elapsed         | 9191       |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01713526 |\n",
      "|    clip_fraction        | 0.0795     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.06      |\n",
      "|    explained_variance   | 0.527      |\n",
      "|    learning_rate        | 1e-05      |\n",
      "|    loss                 | 10.9       |\n",
      "|    n_updates            | 950        |\n",
      "|    policy_gradient_loss | -0.0012    |\n",
      "|    value_loss           | 55.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 9279        |\n",
      "|    total_timesteps      | 49664       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013866825 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | -0.241      |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 5.29        |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | 0.00277     |\n",
      "|    value_loss           | 42.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 9371        |\n",
      "|    total_timesteps      | 50176       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012399889 |\n",
      "|    clip_fraction        | 0.083       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.749       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 114         |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | 0.00126     |\n",
      "|    value_loss           | 275         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 9467        |\n",
      "|    total_timesteps      | 50688       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005693409 |\n",
      "|    clip_fraction        | 0.0518      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.972      |\n",
      "|    explained_variance   | 0.853       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 67.3        |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | -0.00479    |\n",
      "|    value_loss           | 148         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 9566        |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012835592 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.971      |\n",
      "|    explained_variance   | 0.671       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 144         |\n",
      "|    n_updates            | 990         |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    value_loss           | 372         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 101         |\n",
      "|    time_elapsed         | 9668        |\n",
      "|    total_timesteps      | 51712       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011811616 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.901      |\n",
      "|    explained_variance   | 0.633       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 325         |\n",
      "|    n_updates            | 1000        |\n",
      "|    policy_gradient_loss | -0.00187    |\n",
      "|    value_loss           | 550         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 5          |\n",
      "|    iterations           | 102        |\n",
      "|    time_elapsed         | 9766       |\n",
      "|    total_timesteps      | 52224      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03262768 |\n",
      "|    clip_fraction        | 0.225      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.885     |\n",
      "|    explained_variance   | 0.366      |\n",
      "|    learning_rate        | 1e-05      |\n",
      "|    loss                 | 114        |\n",
      "|    n_updates            | 1010       |\n",
      "|    policy_gradient_loss | -0.00584   |\n",
      "|    value_loss           | 648        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 5          |\n",
      "|    iterations           | 103        |\n",
      "|    time_elapsed         | 9862       |\n",
      "|    total_timesteps      | 52736      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01633771 |\n",
      "|    clip_fraction        | 0.162      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.922     |\n",
      "|    explained_variance   | 0.718      |\n",
      "|    learning_rate        | 1e-05      |\n",
      "|    loss                 | 271        |\n",
      "|    n_updates            | 1020       |\n",
      "|    policy_gradient_loss | -0.0092    |\n",
      "|    value_loss           | 424        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 104          |\n",
      "|    time_elapsed         | 9971         |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0089164125 |\n",
      "|    clip_fraction        | 0.0404       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.94        |\n",
      "|    explained_variance   | 0.781        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 143          |\n",
      "|    n_updates            | 1030         |\n",
      "|    policy_gradient_loss | -0.00461     |\n",
      "|    value_loss           | 311          |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 5         |\n",
      "|    iterations           | 105       |\n",
      "|    time_elapsed         | 10089     |\n",
      "|    total_timesteps      | 53760     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0206815 |\n",
      "|    clip_fraction        | 0.24      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.899    |\n",
      "|    explained_variance   | 0.393     |\n",
      "|    learning_rate        | 1e-05     |\n",
      "|    loss                 | 93.1      |\n",
      "|    n_updates            | 1040      |\n",
      "|    policy_gradient_loss | -0.0138   |\n",
      "|    value_loss           | 294       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 5          |\n",
      "|    iterations           | 106        |\n",
      "|    time_elapsed         | 10189      |\n",
      "|    total_timesteps      | 54272      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00986932 |\n",
      "|    clip_fraction        | 0.101      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.49      |\n",
      "|    explained_variance   | 0.672      |\n",
      "|    learning_rate        | 1e-05      |\n",
      "|    loss                 | 98.4       |\n",
      "|    n_updates            | 1050       |\n",
      "|    policy_gradient_loss | -0.0013    |\n",
      "|    value_loss           | 528        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 107         |\n",
      "|    time_elapsed         | 10288       |\n",
      "|    total_timesteps      | 54784       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014225529 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.82       |\n",
      "|    explained_variance   | -0.619      |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 0.0171      |\n",
      "|    n_updates            | 1060        |\n",
      "|    policy_gradient_loss | -0.00888    |\n",
      "|    value_loss           | 0.391       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 108         |\n",
      "|    time_elapsed         | 10385       |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008203374 |\n",
      "|    clip_fraction        | 0.0764      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.8        |\n",
      "|    explained_variance   | -0.103      |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 0.154       |\n",
      "|    n_updates            | 1070        |\n",
      "|    policy_gradient_loss | -0.00752    |\n",
      "|    value_loss           | 0.352       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 109          |\n",
      "|    time_elapsed         | 10483        |\n",
      "|    total_timesteps      | 55808        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026464036 |\n",
      "|    clip_fraction        | 0.0162       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.81        |\n",
      "|    explained_variance   | -0.476       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.165        |\n",
      "|    n_updates            | 1080         |\n",
      "|    policy_gradient_loss | -0.00177     |\n",
      "|    value_loss           | 0.388        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 110         |\n",
      "|    time_elapsed         | 10591       |\n",
      "|    total_timesteps      | 56320       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011879727 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.83       |\n",
      "|    explained_variance   | -0.0744     |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 0.0684      |\n",
      "|    n_updates            | 1090        |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    value_loss           | 0.17        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 5          |\n",
      "|    iterations           | 111        |\n",
      "|    time_elapsed         | 10694      |\n",
      "|    total_timesteps      | 56832      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01238939 |\n",
      "|    clip_fraction        | 0.0641     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.82      |\n",
      "|    explained_variance   | 0.102      |\n",
      "|    learning_rate        | 1e-05      |\n",
      "|    loss                 | 0.104      |\n",
      "|    n_updates            | 1100       |\n",
      "|    policy_gradient_loss | -0.00569   |\n",
      "|    value_loss           | 0.261      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 112         |\n",
      "|    time_elapsed         | 10795       |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012959646 |\n",
      "|    clip_fraction        | 0.0596      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.8        |\n",
      "|    explained_variance   | -0.156      |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 0.0436      |\n",
      "|    n_updates            | 1110        |\n",
      "|    policy_gradient_loss | -0.00664    |\n",
      "|    value_loss           | 0.136       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 113         |\n",
      "|    time_elapsed         | 10897       |\n",
      "|    total_timesteps      | 57856       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002491009 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.79       |\n",
      "|    explained_variance   | 0.127       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 3.81        |\n",
      "|    n_updates            | 1120        |\n",
      "|    policy_gradient_loss | -0.00124    |\n",
      "|    value_loss           | 8.09        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 114         |\n",
      "|    time_elapsed         | 11005       |\n",
      "|    total_timesteps      | 58368       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013509917 |\n",
      "|    clip_fraction        | 0.0688      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.83       |\n",
      "|    explained_variance   | -0.499      |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 0.0596      |\n",
      "|    n_updates            | 1130        |\n",
      "|    policy_gradient_loss | -0.00685    |\n",
      "|    value_loss           | 0.203       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 115         |\n",
      "|    time_elapsed         | 11109       |\n",
      "|    total_timesteps      | 58880       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012260278 |\n",
      "|    clip_fraction        | 0.0443      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.83       |\n",
      "|    explained_variance   | -0.0816     |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 0.0729      |\n",
      "|    n_updates            | 1140        |\n",
      "|    policy_gradient_loss | -0.00487    |\n",
      "|    value_loss           | 0.185       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 116         |\n",
      "|    time_elapsed         | 11208       |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015163066 |\n",
      "|    clip_fraction        | 0.0809      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.76       |\n",
      "|    explained_variance   | -0.0508     |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 0.136       |\n",
      "|    n_updates            | 1150        |\n",
      "|    policy_gradient_loss | -0.00907    |\n",
      "|    value_loss           | 0.131       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 117         |\n",
      "|    time_elapsed         | 11311       |\n",
      "|    total_timesteps      | 59904       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016387515 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.74       |\n",
      "|    explained_variance   | -0.0441     |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 0.102       |\n",
      "|    n_updates            | 1160        |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 0.259       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 118          |\n",
      "|    time_elapsed         | 11414        |\n",
      "|    total_timesteps      | 60416        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0107567925 |\n",
      "|    clip_fraction        | 0.0531       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.79        |\n",
      "|    explained_variance   | 0.678        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.251        |\n",
      "|    n_updates            | 1170         |\n",
      "|    policy_gradient_loss | -0.0093      |\n",
      "|    value_loss           | 0.416        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 119         |\n",
      "|    time_elapsed         | 11518       |\n",
      "|    total_timesteps      | 60928       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012036586 |\n",
      "|    clip_fraction        | 0.0898      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.77       |\n",
      "|    explained_variance   | -0.17       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 0.0836      |\n",
      "|    n_updates            | 1180        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    value_loss           | 0.292       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 120         |\n",
      "|    time_elapsed         | 11622       |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010238945 |\n",
      "|    clip_fraction        | 0.0445      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.76       |\n",
      "|    explained_variance   | -0.434      |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 0.139       |\n",
      "|    n_updates            | 1190        |\n",
      "|    policy_gradient_loss | -0.00654    |\n",
      "|    value_loss           | 0.336       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 121          |\n",
      "|    time_elapsed         | 11726        |\n",
      "|    total_timesteps      | 61952        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070676436 |\n",
      "|    clip_fraction        | 0.0752       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.77        |\n",
      "|    explained_variance   | -0.0511      |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 0.126        |\n",
      "|    n_updates            | 1200         |\n",
      "|    policy_gradient_loss | -0.00643     |\n",
      "|    value_loss           | 0.252        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 122         |\n",
      "|    time_elapsed         | 11831       |\n",
      "|    total_timesteps      | 62464       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008779385 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.7        |\n",
      "|    explained_variance   | 0.497       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 21.7        |\n",
      "|    n_updates            | 1210        |\n",
      "|    policy_gradient_loss | -0.00516    |\n",
      "|    value_loss           | 125         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 5          |\n",
      "|    iterations           | 123        |\n",
      "|    time_elapsed         | 11930      |\n",
      "|    total_timesteps      | 62976      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01717456 |\n",
      "|    clip_fraction        | 0.099      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.76      |\n",
      "|    explained_variance   | -0.03      |\n",
      "|    learning_rate        | 1e-05      |\n",
      "|    loss                 | 0.109      |\n",
      "|    n_updates            | 1220       |\n",
      "|    policy_gradient_loss | -0.0102    |\n",
      "|    value_loss           | 0.334      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 124         |\n",
      "|    time_elapsed         | 12043       |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011125559 |\n",
      "|    clip_fraction        | 0.0635      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.7        |\n",
      "|    explained_variance   | 0.85        |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 0.665       |\n",
      "|    n_updates            | 1230        |\n",
      "|    policy_gradient_loss | -0.00702    |\n",
      "|    value_loss           | 1.44        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 125         |\n",
      "|    time_elapsed         | 12154       |\n",
      "|    total_timesteps      | 64000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006893075 |\n",
      "|    clip_fraction        | 0.0219      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.946       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 47.1        |\n",
      "|    n_updates            | 1240        |\n",
      "|    policy_gradient_loss | -0.00577    |\n",
      "|    value_loss           | 232         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 126          |\n",
      "|    time_elapsed         | 12256        |\n",
      "|    total_timesteps      | 64512        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011657916 |\n",
      "|    clip_fraction        | 0.0121       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.83        |\n",
      "|    explained_variance   | 0.458        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 281          |\n",
      "|    n_updates            | 1250         |\n",
      "|    policy_gradient_loss | -0.0005      |\n",
      "|    value_loss           | 778          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 127         |\n",
      "|    time_elapsed         | 12357       |\n",
      "|    total_timesteps      | 65024       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004612361 |\n",
      "|    clip_fraction        | 0.0268      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.828      |\n",
      "|    explained_variance   | 0.626       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 379         |\n",
      "|    n_updates            | 1260        |\n",
      "|    policy_gradient_loss | -0.000972   |\n",
      "|    value_loss           | 635         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 128         |\n",
      "|    time_elapsed         | 12448       |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009851865 |\n",
      "|    clip_fraction        | 0.0127      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.796      |\n",
      "|    explained_variance   | 0.528       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 357         |\n",
      "|    n_updates            | 1270        |\n",
      "|    policy_gradient_loss | -0.00304    |\n",
      "|    value_loss           | 752         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 129          |\n",
      "|    time_elapsed         | 12540        |\n",
      "|    total_timesteps      | 66048        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062702796 |\n",
      "|    clip_fraction        | 0.0621       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.834       |\n",
      "|    explained_variance   | 0.79         |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 34.2         |\n",
      "|    n_updates            | 1280         |\n",
      "|    policy_gradient_loss | -0.000565    |\n",
      "|    value_loss           | 216          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 5          |\n",
      "|    iterations           | 130        |\n",
      "|    time_elapsed         | 12626      |\n",
      "|    total_timesteps      | 66560      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02496414 |\n",
      "|    clip_fraction        | 0.0865     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.842     |\n",
      "|    explained_variance   | 0.465      |\n",
      "|    learning_rate        | 1e-05      |\n",
      "|    loss                 | 36.8       |\n",
      "|    n_updates            | 1290       |\n",
      "|    policy_gradient_loss | 0.00194    |\n",
      "|    value_loss           | 125        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 131          |\n",
      "|    time_elapsed         | 12722        |\n",
      "|    total_timesteps      | 67072        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026676976 |\n",
      "|    clip_fraction        | 0.0533       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.704       |\n",
      "|    explained_variance   | 0.724        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 79.7         |\n",
      "|    n_updates            | 1300         |\n",
      "|    policy_gradient_loss | -0.00319     |\n",
      "|    value_loss           | 204          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 132         |\n",
      "|    time_elapsed         | 12809       |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008257222 |\n",
      "|    clip_fraction        | 0.0508      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.669      |\n",
      "|    explained_variance   | 0.696       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 182         |\n",
      "|    n_updates            | 1310        |\n",
      "|    policy_gradient_loss | -0.00175    |\n",
      "|    value_loss           | 445         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 133         |\n",
      "|    time_elapsed         | 12910       |\n",
      "|    total_timesteps      | 68096       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008386325 |\n",
      "|    clip_fraction        | 0.0264      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.679      |\n",
      "|    explained_variance   | 0.673       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 79          |\n",
      "|    n_updates            | 1320        |\n",
      "|    policy_gradient_loss | -0.00218    |\n",
      "|    value_loss           | 268         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 134          |\n",
      "|    time_elapsed         | 13015        |\n",
      "|    total_timesteps      | 68608        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006883405 |\n",
      "|    clip_fraction        | 0.00605      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.521       |\n",
      "|    explained_variance   | 0.666        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 160          |\n",
      "|    n_updates            | 1330         |\n",
      "|    policy_gradient_loss | -0.000501    |\n",
      "|    value_loss           | 405          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 135          |\n",
      "|    time_elapsed         | 13117        |\n",
      "|    total_timesteps      | 69120        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057205344 |\n",
      "|    clip_fraction        | 0.068        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.664       |\n",
      "|    explained_variance   | 0.914        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 7.77         |\n",
      "|    n_updates            | 1340         |\n",
      "|    policy_gradient_loss | -0.00256     |\n",
      "|    value_loss           | 52.5         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 136          |\n",
      "|    time_elapsed         | 13220        |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019154578 |\n",
      "|    clip_fraction        | 0.0084       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.484       |\n",
      "|    explained_variance   | 0.658        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 106          |\n",
      "|    n_updates            | 1350         |\n",
      "|    policy_gradient_loss | -0.00275     |\n",
      "|    value_loss           | 470          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 137          |\n",
      "|    time_elapsed         | 13311        |\n",
      "|    total_timesteps      | 70144        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046000723 |\n",
      "|    clip_fraction        | 0.057        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.508       |\n",
      "|    explained_variance   | 0.753        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 41.9         |\n",
      "|    n_updates            | 1360         |\n",
      "|    policy_gradient_loss | -0.00346     |\n",
      "|    value_loss           | 158          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 138         |\n",
      "|    time_elapsed         | 13401       |\n",
      "|    total_timesteps      | 70656       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003942804 |\n",
      "|    clip_fraction        | 0.0479      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.544      |\n",
      "|    explained_variance   | 0.411       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 280         |\n",
      "|    n_updates            | 1370        |\n",
      "|    policy_gradient_loss | -0.0014     |\n",
      "|    value_loss           | 515         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 5          |\n",
      "|    iterations           | 139        |\n",
      "|    time_elapsed         | 13494      |\n",
      "|    total_timesteps      | 71168      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01042747 |\n",
      "|    clip_fraction        | 0.0754     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.62      |\n",
      "|    explained_variance   | 0.341      |\n",
      "|    learning_rate        | 1e-05      |\n",
      "|    loss                 | 83.4       |\n",
      "|    n_updates            | 1380       |\n",
      "|    policy_gradient_loss | -0.00473   |\n",
      "|    value_loss           | 276        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 140          |\n",
      "|    time_elapsed         | 13595        |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0100078415 |\n",
      "|    clip_fraction        | 0.0422       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.656       |\n",
      "|    explained_variance   | 0.599        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 24.8         |\n",
      "|    n_updates            | 1390         |\n",
      "|    policy_gradient_loss | -0.00311     |\n",
      "|    value_loss           | 148          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 5          |\n",
      "|    iterations           | 141        |\n",
      "|    time_elapsed         | 13703      |\n",
      "|    total_timesteps      | 72192      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00301392 |\n",
      "|    clip_fraction        | 0.027      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.587     |\n",
      "|    explained_variance   | 0.603      |\n",
      "|    learning_rate        | 1e-05      |\n",
      "|    loss                 | 72.2       |\n",
      "|    n_updates            | 1400       |\n",
      "|    policy_gradient_loss | 0.000871   |\n",
      "|    value_loss           | 248        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 142          |\n",
      "|    time_elapsed         | 13794        |\n",
      "|    total_timesteps      | 72704        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050199516 |\n",
      "|    clip_fraction        | 0.0715       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.648       |\n",
      "|    explained_variance   | 0.472        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 347          |\n",
      "|    n_updates            | 1410         |\n",
      "|    policy_gradient_loss | -0.0047      |\n",
      "|    value_loss           | 688          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 143         |\n",
      "|    time_elapsed         | 13893       |\n",
      "|    total_timesteps      | 73216       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004274179 |\n",
      "|    clip_fraction        | 0.0318      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.741      |\n",
      "|    explained_variance   | 0.913       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 58.1        |\n",
      "|    n_updates            | 1420        |\n",
      "|    policy_gradient_loss | -0.00327    |\n",
      "|    value_loss           | 126         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 144         |\n",
      "|    time_elapsed         | 13995       |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004372351 |\n",
      "|    clip_fraction        | 0.0297      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.766      |\n",
      "|    explained_variance   | 0.704       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 83          |\n",
      "|    n_updates            | 1430        |\n",
      "|    policy_gradient_loss | -0.00477    |\n",
      "|    value_loss           | 199         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 145         |\n",
      "|    time_elapsed         | 14100       |\n",
      "|    total_timesteps      | 74240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018262438 |\n",
      "|    clip_fraction        | 0.0543      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.701      |\n",
      "|    explained_variance   | 0.464       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 171         |\n",
      "|    n_updates            | 1440        |\n",
      "|    policy_gradient_loss | -0.00165    |\n",
      "|    value_loss           | 723         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 146         |\n",
      "|    time_elapsed         | 14217       |\n",
      "|    total_timesteps      | 74752       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004263173 |\n",
      "|    clip_fraction        | 0.0084      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.6        |\n",
      "|    explained_variance   | 0.844       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 63.5        |\n",
      "|    n_updates            | 1450        |\n",
      "|    policy_gradient_loss | -0.000529   |\n",
      "|    value_loss           | 109         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 147         |\n",
      "|    time_elapsed         | 14331       |\n",
      "|    total_timesteps      | 75264       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006115308 |\n",
      "|    clip_fraction        | 0.0844      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.569      |\n",
      "|    explained_variance   | 0.769       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 132         |\n",
      "|    n_updates            | 1460        |\n",
      "|    policy_gradient_loss | -0.00765    |\n",
      "|    value_loss           | 260         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 148          |\n",
      "|    time_elapsed         | 14438        |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019635994 |\n",
      "|    clip_fraction        | 0.0143       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.463       |\n",
      "|    explained_variance   | 0.39         |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 371          |\n",
      "|    n_updates            | 1470         |\n",
      "|    policy_gradient_loss | -0.00286     |\n",
      "|    value_loss           | 867          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 149         |\n",
      "|    time_elapsed         | 14532       |\n",
      "|    total_timesteps      | 76288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009628894 |\n",
      "|    clip_fraction        | 0.0318      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.506      |\n",
      "|    explained_variance   | 0.436       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 174         |\n",
      "|    n_updates            | 1480        |\n",
      "|    policy_gradient_loss | -0.000727   |\n",
      "|    value_loss           | 443         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 150         |\n",
      "|    time_elapsed         | 14629       |\n",
      "|    total_timesteps      | 76800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002336719 |\n",
      "|    clip_fraction        | 0.0598      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.715      |\n",
      "|    explained_variance   | 0.799       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 67.8        |\n",
      "|    n_updates            | 1490        |\n",
      "|    policy_gradient_loss | -0.0047     |\n",
      "|    value_loss           | 182         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 151          |\n",
      "|    time_elapsed         | 14713        |\n",
      "|    total_timesteps      | 77312        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021506217 |\n",
      "|    clip_fraction        | 0.00527      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.603       |\n",
      "|    explained_variance   | 0.643        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 172          |\n",
      "|    n_updates            | 1500         |\n",
      "|    policy_gradient_loss | 0.001        |\n",
      "|    value_loss           | 482          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 152          |\n",
      "|    time_elapsed         | 14798        |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012685274 |\n",
      "|    clip_fraction        | 0.0902       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.478       |\n",
      "|    explained_variance   | 0.662        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 112          |\n",
      "|    n_updates            | 1510         |\n",
      "|    policy_gradient_loss | 0.00135      |\n",
      "|    value_loss           | 377          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 153         |\n",
      "|    time_elapsed         | 14880       |\n",
      "|    total_timesteps      | 78336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009431757 |\n",
      "|    clip_fraction        | 0.0809      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.545      |\n",
      "|    explained_variance   | 0.819       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 84.4        |\n",
      "|    n_updates            | 1520        |\n",
      "|    policy_gradient_loss | -0.00506    |\n",
      "|    value_loss           | 175         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 154         |\n",
      "|    time_elapsed         | 14957       |\n",
      "|    total_timesteps      | 78848       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006812226 |\n",
      "|    clip_fraction        | 0.085       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.444      |\n",
      "|    explained_variance   | 0.541       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 158         |\n",
      "|    n_updates            | 1530        |\n",
      "|    policy_gradient_loss | 0.00122     |\n",
      "|    value_loss           | 438         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 155          |\n",
      "|    time_elapsed         | 15037        |\n",
      "|    total_timesteps      | 79360        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012611161 |\n",
      "|    clip_fraction        | 0.0084       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.523       |\n",
      "|    explained_variance   | 0.697        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 48.8         |\n",
      "|    n_updates            | 1540         |\n",
      "|    policy_gradient_loss | 0.000503     |\n",
      "|    value_loss           | 105          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 156          |\n",
      "|    time_elapsed         | 15117        |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045785606 |\n",
      "|    clip_fraction        | 0.0504       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.422       |\n",
      "|    explained_variance   | 0.347        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 40.3         |\n",
      "|    n_updates            | 1550         |\n",
      "|    policy_gradient_loss | -0.00411     |\n",
      "|    value_loss           | 133          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 157          |\n",
      "|    time_elapsed         | 15198        |\n",
      "|    total_timesteps      | 80384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005001003 |\n",
      "|    clip_fraction        | 0.00176      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.329       |\n",
      "|    explained_variance   | 0.577        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 110          |\n",
      "|    n_updates            | 1560         |\n",
      "|    policy_gradient_loss | -0.000121    |\n",
      "|    value_loss           | 557          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 158          |\n",
      "|    time_elapsed         | 15279        |\n",
      "|    total_timesteps      | 80896        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026719768 |\n",
      "|    clip_fraction        | 0.0275       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.436       |\n",
      "|    explained_variance   | 0.834        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 61           |\n",
      "|    n_updates            | 1570         |\n",
      "|    policy_gradient_loss | -0.00275     |\n",
      "|    value_loss           | 148          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 159          |\n",
      "|    time_elapsed         | 15360        |\n",
      "|    total_timesteps      | 81408        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018495922 |\n",
      "|    clip_fraction        | 0.0539       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.415       |\n",
      "|    explained_variance   | 0.507        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 153          |\n",
      "|    n_updates            | 1580         |\n",
      "|    policy_gradient_loss | -0.00442     |\n",
      "|    value_loss           | 348          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 160         |\n",
      "|    time_elapsed         | 15439       |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008922173 |\n",
      "|    clip_fraction        | 0.0377      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.51       |\n",
      "|    explained_variance   | 0.684       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 44.9        |\n",
      "|    n_updates            | 1590        |\n",
      "|    policy_gradient_loss | 0.000113    |\n",
      "|    value_loss           | 386         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 161          |\n",
      "|    time_elapsed         | 15520        |\n",
      "|    total_timesteps      | 82432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061241537 |\n",
      "|    clip_fraction        | 0.0631       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.563       |\n",
      "|    explained_variance   | 0.817        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 47.3         |\n",
      "|    n_updates            | 1600         |\n",
      "|    policy_gradient_loss | -0.000189    |\n",
      "|    value_loss           | 120          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 162          |\n",
      "|    time_elapsed         | 15601        |\n",
      "|    total_timesteps      | 82944        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0078057256 |\n",
      "|    clip_fraction        | 0.0785       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.548       |\n",
      "|    explained_variance   | 0.73         |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 74.2         |\n",
      "|    n_updates            | 1610         |\n",
      "|    policy_gradient_loss | -0.00535     |\n",
      "|    value_loss           | 303          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 163          |\n",
      "|    time_elapsed         | 15681        |\n",
      "|    total_timesteps      | 83456        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062854057 |\n",
      "|    clip_fraction        | 0.0301       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.625       |\n",
      "|    explained_variance   | 0.71         |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 46.2         |\n",
      "|    n_updates            | 1620         |\n",
      "|    policy_gradient_loss | -0.00176     |\n",
      "|    value_loss           | 130          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 164         |\n",
      "|    time_elapsed         | 15775       |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008790106 |\n",
      "|    clip_fraction        | 0.0646      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.584      |\n",
      "|    explained_variance   | 0.326       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 130         |\n",
      "|    n_updates            | 1630        |\n",
      "|    policy_gradient_loss | -0.00275    |\n",
      "|    value_loss           | 549         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 165          |\n",
      "|    time_elapsed         | 15867        |\n",
      "|    total_timesteps      | 84480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029890323 |\n",
      "|    clip_fraction        | 0.0529       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.681       |\n",
      "|    explained_variance   | 0.744        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 55.5         |\n",
      "|    n_updates            | 1640         |\n",
      "|    policy_gradient_loss | -0.00435     |\n",
      "|    value_loss           | 134          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 166          |\n",
      "|    time_elapsed         | 15948        |\n",
      "|    total_timesteps      | 84992        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043984144 |\n",
      "|    clip_fraction        | 0.0635       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.624       |\n",
      "|    explained_variance   | 0.756        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 50.7         |\n",
      "|    n_updates            | 1650         |\n",
      "|    policy_gradient_loss | -0.00425     |\n",
      "|    value_loss           | 199          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 167          |\n",
      "|    time_elapsed         | 16023        |\n",
      "|    total_timesteps      | 85504        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018539445 |\n",
      "|    clip_fraction        | 0.0246       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.676       |\n",
      "|    explained_variance   | 0.713        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 75.4         |\n",
      "|    n_updates            | 1660         |\n",
      "|    policy_gradient_loss | -0.000395    |\n",
      "|    value_loss           | 209          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 168         |\n",
      "|    time_elapsed         | 16097       |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006503272 |\n",
      "|    clip_fraction        | 0.0357      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.617      |\n",
      "|    explained_variance   | 0.542       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 289         |\n",
      "|    n_updates            | 1670        |\n",
      "|    policy_gradient_loss | -0.00212    |\n",
      "|    value_loss           | 560         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 169         |\n",
      "|    time_elapsed         | 16169       |\n",
      "|    total_timesteps      | 86528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004756542 |\n",
      "|    clip_fraction        | 0.0689      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.654      |\n",
      "|    explained_variance   | 0.697       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 97.2        |\n",
      "|    n_updates            | 1680        |\n",
      "|    policy_gradient_loss | -0.00129    |\n",
      "|    value_loss           | 237         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 170         |\n",
      "|    time_elapsed         | 16243       |\n",
      "|    total_timesteps      | 87040       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005514143 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.638      |\n",
      "|    explained_variance   | 0.373       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 143         |\n",
      "|    n_updates            | 1690        |\n",
      "|    policy_gradient_loss | -0.004      |\n",
      "|    value_loss           | 673         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 171          |\n",
      "|    time_elapsed         | 16318        |\n",
      "|    total_timesteps      | 87552        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005456547 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.662       |\n",
      "|    explained_variance   | 0.349        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 362          |\n",
      "|    n_updates            | 1700         |\n",
      "|    policy_gradient_loss | 2.82e-05     |\n",
      "|    value_loss           | 748          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 172          |\n",
      "|    time_elapsed         | 16391        |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053553893 |\n",
      "|    clip_fraction        | 0.0941       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.571       |\n",
      "|    explained_variance   | 0.518        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 221          |\n",
      "|    n_updates            | 1710         |\n",
      "|    policy_gradient_loss | -0.00359     |\n",
      "|    value_loss           | 483          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 173         |\n",
      "|    time_elapsed         | 16464       |\n",
      "|    total_timesteps      | 88576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005029769 |\n",
      "|    clip_fraction        | 0.0625      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.633      |\n",
      "|    explained_variance   | 0.585       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 55.2        |\n",
      "|    n_updates            | 1720        |\n",
      "|    policy_gradient_loss | -0.00303    |\n",
      "|    value_loss           | 121         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 174         |\n",
      "|    time_elapsed         | 16536       |\n",
      "|    total_timesteps      | 89088       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021526745 |\n",
      "|    clip_fraction        | 0.0965      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.53       |\n",
      "|    explained_variance   | 0.51        |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 536         |\n",
      "|    n_updates            | 1730        |\n",
      "|    policy_gradient_loss | -0.00416    |\n",
      "|    value_loss           | 547         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 175         |\n",
      "|    time_elapsed         | 16609       |\n",
      "|    total_timesteps      | 89600       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006096607 |\n",
      "|    clip_fraction        | 0.0342      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.506      |\n",
      "|    explained_variance   | 0.505       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 327         |\n",
      "|    n_updates            | 1740        |\n",
      "|    policy_gradient_loss | -0.000557   |\n",
      "|    value_loss           | 443         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 176          |\n",
      "|    time_elapsed         | 16683        |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017724729 |\n",
      "|    clip_fraction        | 0.0248       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.452       |\n",
      "|    explained_variance   | 0.728        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 43.5         |\n",
      "|    n_updates            | 1750         |\n",
      "|    policy_gradient_loss | -0.000779    |\n",
      "|    value_loss           | 111          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 177         |\n",
      "|    time_elapsed         | 16752       |\n",
      "|    total_timesteps      | 90624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008884475 |\n",
      "|    clip_fraction        | 0.0469      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.398      |\n",
      "|    explained_variance   | 0.574       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 60.1        |\n",
      "|    n_updates            | 1760        |\n",
      "|    policy_gradient_loss | -0.00257    |\n",
      "|    value_loss           | 187         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 178          |\n",
      "|    time_elapsed         | 16827        |\n",
      "|    total_timesteps      | 91136        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038750656 |\n",
      "|    clip_fraction        | 0.0234       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.286       |\n",
      "|    explained_variance   | 0.759        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 50.6         |\n",
      "|    n_updates            | 1770         |\n",
      "|    policy_gradient_loss | -0.0019      |\n",
      "|    value_loss           | 126          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 179         |\n",
      "|    time_elapsed         | 16901       |\n",
      "|    total_timesteps      | 91648       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001192967 |\n",
      "|    clip_fraction        | 0.00566     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.294      |\n",
      "|    explained_variance   | 0.851       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 51.3        |\n",
      "|    n_updates            | 1780        |\n",
      "|    policy_gradient_loss | -0.000213   |\n",
      "|    value_loss           | 159         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 180          |\n",
      "|    time_elapsed         | 16973        |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017467815 |\n",
      "|    clip_fraction        | 0.0326       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.326       |\n",
      "|    explained_variance   | 0.809        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 20.9         |\n",
      "|    n_updates            | 1790         |\n",
      "|    policy_gradient_loss | -0.000921    |\n",
      "|    value_loss           | 57.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 181          |\n",
      "|    time_elapsed         | 17044        |\n",
      "|    total_timesteps      | 92672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001954902 |\n",
      "|    clip_fraction        | 0.0186       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.367       |\n",
      "|    explained_variance   | 0.26         |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 217          |\n",
      "|    n_updates            | 1800         |\n",
      "|    policy_gradient_loss | -0.00122     |\n",
      "|    value_loss           | 562          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 182          |\n",
      "|    time_elapsed         | 17115        |\n",
      "|    total_timesteps      | 93184        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058753053 |\n",
      "|    clip_fraction        | 0.0391       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.231       |\n",
      "|    explained_variance   | 0.325        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 381          |\n",
      "|    n_updates            | 1810         |\n",
      "|    policy_gradient_loss | -0.00213     |\n",
      "|    value_loss           | 448          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 183          |\n",
      "|    time_elapsed         | 17189        |\n",
      "|    total_timesteps      | 93696        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024327561 |\n",
      "|    clip_fraction        | 0.0227       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.258       |\n",
      "|    explained_variance   | 0.572        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 14.7         |\n",
      "|    n_updates            | 1820         |\n",
      "|    policy_gradient_loss | -0.00175     |\n",
      "|    value_loss           | 53.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 184          |\n",
      "|    time_elapsed         | 17265        |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012053757 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.271       |\n",
      "|    explained_variance   | 0.804        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 30.3         |\n",
      "|    n_updates            | 1830         |\n",
      "|    policy_gradient_loss | 0.00152      |\n",
      "|    value_loss           | 51.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 185          |\n",
      "|    time_elapsed         | 17339        |\n",
      "|    total_timesteps      | 94720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019587749 |\n",
      "|    clip_fraction        | 0.0113       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.21        |\n",
      "|    explained_variance   | 0.543        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 135          |\n",
      "|    n_updates            | 1840         |\n",
      "|    policy_gradient_loss | -0.00044     |\n",
      "|    value_loss           | 320          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 186          |\n",
      "|    time_elapsed         | 17412        |\n",
      "|    total_timesteps      | 95232        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009375998 |\n",
      "|    clip_fraction        | 0.00605      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.204       |\n",
      "|    explained_variance   | 0.733        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 37.7         |\n",
      "|    n_updates            | 1850         |\n",
      "|    policy_gradient_loss | -0.000113    |\n",
      "|    value_loss           | 127          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 187         |\n",
      "|    time_elapsed         | 17482       |\n",
      "|    total_timesteps      | 95744       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001351205 |\n",
      "|    clip_fraction        | 0.0133      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.192      |\n",
      "|    explained_variance   | 0.291       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 113         |\n",
      "|    n_updates            | 1860        |\n",
      "|    policy_gradient_loss | -0.00285    |\n",
      "|    value_loss           | 437         |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 5             |\n",
      "|    iterations           | 188           |\n",
      "|    time_elapsed         | 17555         |\n",
      "|    total_timesteps      | 96256         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00091948255 |\n",
      "|    clip_fraction        | 0.0102        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.228        |\n",
      "|    explained_variance   | 0.662         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 68.7          |\n",
      "|    n_updates            | 1870          |\n",
      "|    policy_gradient_loss | -0.000274     |\n",
      "|    value_loss           | 140           |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 5           |\n",
      "|    iterations           | 189         |\n",
      "|    time_elapsed         | 17628       |\n",
      "|    total_timesteps      | 96768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002619918 |\n",
      "|    clip_fraction        | 0.0262      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.246      |\n",
      "|    explained_variance   | 0.762       |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 71.2        |\n",
      "|    n_updates            | 1880        |\n",
      "|    policy_gradient_loss | -0.00348    |\n",
      "|    value_loss           | 116         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 190          |\n",
      "|    time_elapsed         | 17700        |\n",
      "|    total_timesteps      | 97280        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009326914 |\n",
      "|    clip_fraction        | 0.00254      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.186       |\n",
      "|    explained_variance   | 0.708        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 60.7         |\n",
      "|    n_updates            | 1890         |\n",
      "|    policy_gradient_loss | -0.000323    |\n",
      "|    value_loss           | 373          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 191          |\n",
      "|    time_elapsed         | 17772        |\n",
      "|    total_timesteps      | 97792        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022109228 |\n",
      "|    clip_fraction        | 0.0127       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.194       |\n",
      "|    explained_variance   | 0.854        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 10.1         |\n",
      "|    n_updates            | 1900         |\n",
      "|    policy_gradient_loss | -0.00166     |\n",
      "|    value_loss           | 48.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 192          |\n",
      "|    time_elapsed         | 17843        |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006028715 |\n",
      "|    clip_fraction        | 0.00195      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.209       |\n",
      "|    explained_variance   | 0.696        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 39.1         |\n",
      "|    n_updates            | 1910         |\n",
      "|    policy_gradient_loss | 0.000345     |\n",
      "|    value_loss           | 110          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 193          |\n",
      "|    time_elapsed         | 17916        |\n",
      "|    total_timesteps      | 98816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040336633 |\n",
      "|    clip_fraction        | 0.017        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.213       |\n",
      "|    explained_variance   | 0.711        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 48.4         |\n",
      "|    n_updates            | 1920         |\n",
      "|    policy_gradient_loss | -0.0035      |\n",
      "|    value_loss           | 161          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 5            |\n",
      "|    iterations           | 194          |\n",
      "|    time_elapsed         | 17990        |\n",
      "|    total_timesteps      | 99328        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009797764 |\n",
      "|    clip_fraction        | 0.00996      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.261       |\n",
      "|    explained_variance   | 0.511        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 74.8         |\n",
      "|    n_updates            | 1930         |\n",
      "|    policy_gradient_loss | -0.000478    |\n",
      "|    value_loss           | 205          |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 5             |\n",
      "|    iterations           | 195           |\n",
      "|    time_elapsed         | 18062         |\n",
      "|    total_timesteps      | 99840         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00067994744 |\n",
      "|    clip_fraction        | 0.00723       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.175        |\n",
      "|    explained_variance   | 0.361         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 171           |\n",
      "|    n_updates            | 1940          |\n",
      "|    policy_gradient_loss | -0.000624     |\n",
      "|    value_loss           | 435           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 5             |\n",
      "|    iterations           | 196           |\n",
      "|    time_elapsed         | 18133         |\n",
      "|    total_timesteps      | 100352        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00048227888 |\n",
      "|    clip_fraction        | 0.00156       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.178        |\n",
      "|    explained_variance   | 0.147         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 23.6          |\n",
      "|    n_updates            | 1950          |\n",
      "|    policy_gradient_loss | 0.000156      |\n",
      "|    value_loss           | 88.3          |\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model_learning(model, 100000, 'None')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd33e8be",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d8d27f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating our model\n",
    "\n",
    "def evaluate_mario(n_steps, render):\n",
    "    \n",
    "    env = set_up_env('SuperMarioBros-v0', SIMPLE_MOVEMENT, True, True, 4, 'last')\n",
    "    \n",
    "    # Start the game \n",
    "    state = env.reset()\n",
    "    steps = 1000\n",
    "    # Loop through the game\n",
    "    rewards = []\n",
    "    for i in range(steps):\n",
    "\n",
    "        action, _ = model.predict(state)\n",
    "        state, reward, done, info = env.step(action)\n",
    "        rewards.append(reward)\n",
    "        if render == True:\n",
    "            env.render()\n",
    "    env.close()  \n",
    "    \n",
    "    return np.sum(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "411201d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total rewards during 1000 steps is 1251.0\n"
     ]
    }
   ],
   "source": [
    "# Single play-through\n",
    "\n",
    "print('The agent recieved a total reward in one playthrough of', evaluate_mario(1000, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41c39b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple play-throughs\n",
    "\n",
    "rewards_list = []\n",
    "n_traj = 10\n",
    "for i in range(n_traj):\n",
    "    rewards_list.append(evaluate_mario(1000, False))\n",
    "print('The average reward after', n_traj, 'trajectories is', np.mean(rewards_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352bbc3f",
   "metadata": {},
   "source": [
    "# Saving and Reloading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2fda7d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "\n",
    "model.save('Models/PPO.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1681f0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the model\n",
    "\n",
    "model = PPO.load('Models/PPO.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
